{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = pd.read_csv(\"./Dataset/train_feature.csv\")\n",
    "data_label = pd.read_csv(\"./Dataset/train_label.csv\")\n",
    "test_feature = pd.read_csv(\"./Dataset/test_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.116155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  10000.000000\n",
       "mean       1.488900\n",
       "std        1.116155\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        2.000000\n",
       "max        3.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始数据合并与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_feature,data_label],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 0, 49.06611570247934)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = data.columns\n",
    "cntnull = []\n",
    "for i in range(len(names)):\n",
    "    cntnull.append(data[names[i]].isnull().sum())\n",
    "max(cntnull), min(cntnull), sum(cntnull)/len(cntnull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.804220</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.157242</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>1.122944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.732584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-15.118262</td>\n",
       "      <td>0.590192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.276093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583108</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.852767</td>\n",
       "      <td>4.685032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.601408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.691250</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.907026</td>\n",
       "      <td>0.927391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.129846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.867626</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.992557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173169</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.165119</td>\n",
       "      <td>7.096296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.474665</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.256328</td>\n",
       "      <td>5838.357604</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758844</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>11.567181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.226799</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>50.0</td>\n",
       "      <td>6.267244</td>\n",
       "      <td>0.446096</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.586553</td>\n",
       "      <td>...</td>\n",
       "      <td>2.267124</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.132499</td>\n",
       "      <td>1.310972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.279090</td>\n",
       "      <td>0.143929</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435415</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>1.328274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.707751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.814346</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.580825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334893</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.237845</td>\n",
       "      <td>1.219853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.555282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.271178</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.266668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366215</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>1.428329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.565160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36.0</td>\n",
       "      <td>9.613106</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.449848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.728888</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.049360</td>\n",
       "      <td>0.286351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.174472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5486 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1    feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          48.0   9.804220     0.064283        6.0        5.0      211.0   \n",
       "1          45.0 -15.118262     0.590192       10.0        2.0      141.0   \n",
       "2          56.0   1.691250     0.173249        8.0        1.0      251.0   \n",
       "3          50.0   5.867626     0.004743        8.0        3.0      186.0   \n",
       "6          56.0   4.256328  5838.357604        9.0        5.0      222.0   \n",
       "...         ...        ...          ...        ...        ...        ...   \n",
       "9994       50.0   6.267244     0.446096       11.0        2.0      186.0   \n",
       "9995       67.0   1.279090     0.143929       10.0        3.0      210.0   \n",
       "9996       56.0   4.814346     0.697155        6.0        6.0      267.0   \n",
       "9997       57.0  -0.271178     0.579603        8.0        5.0      168.0   \n",
       "9999       36.0   9.613106     0.680197        8.0        4.0      162.0   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0          45.0        8.0        3.0   2.711200  ...     1.157242   \n",
       "1          48.0        7.0        1.0   3.276093  ...     0.583108   \n",
       "2          47.0        6.0        1.0   1.082628  ...     0.741096   \n",
       "3          39.0        8.0        1.0   2.992557  ...     1.173169   \n",
       "6          61.0        6.0        2.0   0.408384  ...     0.758844   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9994       47.0        9.0        8.0   0.586553  ...     2.267124   \n",
       "9995       51.0        8.0        1.0   0.670449  ...     1.435415   \n",
       "9996       44.0        9.0        2.0   0.580825  ...     0.334893   \n",
       "9997       57.0        8.0        5.0  14.266668  ...     1.366215   \n",
       "9999       52.0        7.0        1.0   3.449848  ...     1.728888   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0            44.0     0.027881     1.122944          0.0         47.0   \n",
       "1            62.0     0.852767     4.685032          1.0         38.0   \n",
       "2            62.0     0.907026     0.927391          2.0         53.0   \n",
       "3            60.0     0.165119     7.096296          1.0         56.0   \n",
       "6            44.0     0.029199    11.567181          0.0         63.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9994         44.0     0.132499     1.310972          2.0         63.0   \n",
       "9995         50.0     0.607483     1.328274          4.0         49.0   \n",
       "9996         63.0     0.237845     1.219853          1.0         55.0   \n",
       "9997         45.0     0.491556     1.428329          2.0         59.0   \n",
       "9999         50.0     0.049360     0.286351          3.0         50.0   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        1.732584          2.0         52.0      0  \n",
       "1        0.601408          2.0         44.0      0  \n",
       "2        2.129846          1.0         46.0      0  \n",
       "3        0.474665          2.0         38.0      2  \n",
       "6        0.226799          2.0         43.0      0  \n",
       "...           ...          ...          ...    ...  \n",
       "9994     0.039158          3.0         44.0      1  \n",
       "9995     0.707751          1.0         52.0      1  \n",
       "9996     0.555282          4.0         52.0      3  \n",
       "9997     1.565160          2.0         41.0      0  \n",
       "9999     1.174472          1.0         54.0      0  \n",
       "\n",
       "[5486 rows x 121 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一下全部删去空值的时候剩下什么\n",
    "data0 = data.copy(deep=True).dropna()\n",
    "data0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清理了太多数据，考虑还是填充，用前一行的值填补空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='pad', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000.00000\n",
       "mean       1526.86640\n",
       "std       22861.25555\n",
       "min          24.00000\n",
       "25%          45.00000\n",
       "50%          50.00000\n",
       "75%          54.00000\n",
       "max      632196.00000\n",
       "Name: feature_116, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_116'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEWElEQVR4nO3dfVSU550+8GtAGUcCUxBhGLHCStOkC9quaVV0Akg0MaBlkW4rlk1Os000QWMk3Q1ud8VsVjweNJvGt7X763Z7UmV7cLSJGkSyokMcX4JhZbRWY0Uib2MpzCDhRWa+vz+yPPUBIxBTps5zfc6Zc5znvpi5J+eE+XI/94tORAREREREGhTg6w4QERER+QoLISIiItIsFkJERESkWSyEiIiISLNYCBEREZFmsRAiIiIizWIhRERERJrFQoiIiIg0a4yvO/Dnzuv1orGxESEhIdDpdL7uDhEREQ2DiKCjowNmsxkBAZ897sNCaAiNjY2YPHmyr7tBREREn8PHH3+MmJiYz2xnITSEkJAQAJ/+hwwNDfVxb4iIiGg43G43Jk+erHyPfxYWQkPovx0WGhrKQoiIiOg+M9S0Fk6WJiIiIs1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZnFDRSLSJI/HA5vNhqamJkRHR8NisSAwMNDX3SKiUcYRISLSHKvVivj4eKSmpiInJwepqamIj4+H1Wr1ddeIaJSxECIiTbFarcjOzkZiYiLsdjs6Ojpgt9uRmJiI7OxsFkNEGqMTEfF1J/6cud1uGI1GuFwunjVGdJ/zeDyIj49HYmIi9u/fj4CAP/4t6PV6kZmZCYfDgcuXL/M2GdF9brjf3xwRIiLNsNlsqKurw9q1a1VFEAAEBASgoKAAV69ehc1m81EPiWi0cbI0EWlGU1MTACAhIeGOk6UTEhJUOSLyfyyEiEgzoqOjAQBbt27Fv//7v6Ourk5pi42NxbPPPqvKEZH/460xItIMi8WCiRMnoqCgAAkJCarJ0gkJCVi7di0iIyNhsVh83VUiGiUshIhIU3Q6nfJvEVEeRKRNLISISDNsNhucTieKiorgcDiQlJSE0NBQJCUl4fz589iwYQOcTicnSxNpCAshItKM/knQeXl5+Oijj3D06FHs3r0bR48exeXLl5GXl6fKEZH/42RpItKM/knQDocDs2bNQkpKiqrd4XCockTk/zgiRESaYbFYEBsbiw0bNsDr9aravF4vioqKEBcXx8nSRBrCQoiINCMwMBCbN2/GgQMHkJmZqVo1lpmZiQMHDqC4uJi7ShNpCG+NEZGmZGVlobS0FPn5+UhKSlKux8XFobS0FFlZWT7sHRGNNp41NgSeNUbkn+60szRHgoj8x3C/vzkiRESaFBgYOGiyNBFpD+cIERERkWaNuBBqaGjA97//fUyYMAHjx4/H17/+dVRXVyvtIoLCwkKYzWYYDAakpKTg/Pnzqtfo6enBypUrERERgeDgYCxevBjXr19XZdra2pCbmwuj0Qij0Yjc3Fy0t7erMvX19Vi0aBGCg4MRERGBVatWobe3V5Wpra1FcnIyDAYDJk2ahFdffZW7yBIRERGAERZCbW1tmDNnDsaOHYt3330XFy5cwObNm/GlL31JyWzatAlbtmzB1q1bcebMGZhMJsyfPx8dHR1KZvXq1di3bx9KSkpQVVWFmzdvIiMjAx6PR8nk5OSgpqYGZWVlKCsrQ01NDXJzc5V2j8eD9PR0dHZ2oqqqCiUlJdi7dy/y8/OVjNvtxvz582E2m3HmzBm8+eabKC4uxpYtWz7PfysiIiLyNzIC//AP/yBz5879zHav1ysmk0k2btyoXOvu7haj0Sg7d+4UEZH29nYZO3aslJSUKJmGhgYJCAiQsrIyERG5cOGCAJCTJ08qGbvdLgDk4sWLIiJy6NAhCQgIkIaGBiWzZ88e0ev14nK5RERk+/btYjQapbu7W8kUFRWJ2WwWr9c7rM/scrkEgPKaRERE9OdvuN/fIxoRevvtt/HII4/gO9/5DiIjI/GNb3wDP/3pT5X2q1evorm5GQsWLFCu6fV6JCcn48SJEwCA6upq3Lp1S5Uxm81ISEhQMna7HUajETNnzlQys2bNgtFoVGUSEhJgNpuVzOOPP46enh7lVp3dbkdycjL0er0q09jYiLq6upF8dCIiIvJDIyqEfve732HHjh34yle+gsOHD2P58uVYtWoVfvGLXwAAmpubAQBRUVGqn4uKilLampubERQUhLCwsLtmIiMjB71/ZGSkKjPwfcLCwhAUFHTXTP/z/sxAPT09cLvdqgcRERH5pxEtn/d6vXjkkUewYcMGAMA3vvENnD9/Hjt27MDf/u3fKjmdTqf6OREZdG2ggZk75b+IjPzfROnP6k9RURHWr19/174SERGRfxjRiFB0dDS+9rWvqa49/PDDqK+vBwCYTCYAg0dbnE6nMhJjMpnQ29uLtra2u2ZaWloGvf+NGzdUmYHv09bWhlu3bt0143Q6AQwetepXUFAAl8ulPD7++OM75oiIiOj+N6JCaM6cOfjtb3+runbp0iVMmTIFwKdb1JtMJhw5ckRp7+3txbFjx5St7GfMmIGxY8eqMk1NTXA4HEpm9uzZcLlcOH36tJI5deoUXC6XKuNwONDU1KRkysvLodfrMWPGDCVz/Phx1ZL68vJymM1mxMbG3vEz6vV6hIaGqh5ERETkp0YyA/v06dMyZswY+dd//Ve5fPmy/PKXv5Tx48fLW2+9pWQ2btwoRqNRrFar1NbWytKlSyU6OlrcbreSWb58ucTExEhFRYWcPXtW5s2bJ9OnT5e+vj4l88QTT8i0adPEbreL3W6XxMREycjIUNr7+vokISFB0tLS5OzZs1JRUSExMTGSl5enZNrb2yUqKkqWLl0qtbW1YrVaJTQ0VIqLi4f9mblqjIiI6P4z3O/vERVCIiLvvPOOJCQkiF6vl4ceekh27dqlavd6vbJu3ToxmUyi1+vl0UcfldraWlWmq6tL8vLyJDw8XAwGg2RkZEh9fb0q09raKsuWLZOQkBAJCQmRZcuWSVtbmypz7do1SU9PF4PBIOHh4ZKXl6daKi8icu7cObFYLKLX68VkMklhYeGwl86LsBAiIiK6Hw33+5uHrg6Bh64SERHdf4b7/c2zxoiIiEizWAgRERGRZrEQIiIiIs1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZo3xdQeIiHzB4/HAZrOhqakJ0dHRsFgsCAwM9HW3iGiUcUSIiDTHarUiPj4eqampyMnJQWpqKuLj42G1Wn3dNSIaZSyEiEhTrFYrsrOzkZiYCLvdjo6ODtjtdiQmJiI7O5vFEJHG8PT5IfD0eSL/4fF4EB8fj8TEROzfvx8BAX/8W9Dr9SIzMxMOhwOXL1/mbTKi+xxPnyciGsBms6Gurg5r165VFUEAEBAQgIKCAly9ehU2m81HPSSi0cZCiIg0o6mpCQCQkJBwx/b+6/05IvJ/LISISDOio6MBAA6H447t/df7c0Tk/1gIEZFmWCwWxMbGYsOGDfB6vao2r9eLoqIixMXFwWKx+KiHRDTaWAgRkWYEBgZi8+bNOHDgADIzM1WrxjIzM3HgwAEUFxdzojSRhnBDRSLSlKysLJSWliI/Px9JSUnK9bi4OJSWliIrK8uHvSOi0cbl80Pg8nki/9Tb24vt27fjypUrmDp1Kp5//nkEBQX5ultE9AUZ7vc3R4SISHOsVivy8/NRV1enXHvjjTewefNmjggRaQznCBGRpnBnaSK6HW+NDYG3xoj8B3eWJtIO7ixNRDQAd5YmooFYCBGRZnBnaSIaiIUQEWkGd5YmooFYCBGRZnBnaSIaiIUQEWkGd5YmooG4jxARaQp3liai23H5/BC4fJ7IP3k8HthsNjQ1NSE6OhoWi4UjQUR+hDtLExHdRWBgIFJSUnzdDSLyMc4RIiIiIs1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIURERESaxUKIiIiINGtEhVBhYSF0Op3qYTKZlHYRQWFhIcxmMwwGA1JSUnD+/HnVa/T09GDlypWIiIhAcHAwFi9ejOvXr6sybW1tyM3NhdFohNFoRG5uLtrb21WZ+vp6LFq0CMHBwYiIiMCqVavQ29urytTW1iI5ORkGgwGTJk3Cq6++Cp4xS0RERP1GPCL0l3/5l2hqalIetbW1StumTZuwZcsWbN26FWfOnIHJZML8+fPR0dGhZFavXo19+/ahpKQEVVVVuHnzJjIyMuDxeJRMTk4OampqUFZWhrKyMtTU1CA3N1dp93g8SE9PR2dnJ6qqqlBSUoK9e/ciPz9fybjdbsyfPx9msxlnzpzBm2++ieLiYmzZsmXE/5GIiIjIT8kIrFu3TqZPn37HNq/XKyaTSTZu3Khc6+7uFqPRKDt37hQRkfb2dhk7dqyUlJQomYaGBgkICJCysjIREblw4YIAkJMnTyoZu90uAOTixYsiInLo0CEJCAiQhoYGJbNnzx7R6/XicrlERGT79u1iNBqlu7tbyRQVFYnZbBav1zvsz+xyuQSA8rpERET052+4398jHhG6fPkyzGYz4uLi8L3vfQ+/+93vAABXr15Fc3MzFixYoGT1ej2Sk5Nx4sQJAEB1dTVu3bqlypjNZiQkJCgZu90Oo9GImTNnKplZs2bBaDSqMgkJCTCbzUrm8ccfR09PD6qrq5VMcnIy9Hq9KtPY2Ii6urrP/Hw9PT1wu92qBxEREfmnERVCM2fOxC9+8QscPnwYP/3pT9Hc3IykpCS0traiubkZABAVFaX6maioKKWtubkZQUFBCAsLu2smMjJy0HtHRkaqMgPfJywsDEFBQXfN9D/vz9xJUVGRMjfJaDRi8uTJd/+PQkRERPetERVCCxcuxJIlS5CYmIjHHnsMBw8eBAD813/9l5LR6XSqnxGRQdcGGpi5U/6LyMj/TZS+W38KCgrgcrmUx8cff3zXvhMREdH9656WzwcHByMxMRGXL19WVo8NHG1xOp3KSIzJZEJvby/a2trummlpaRn0Xjdu3FBlBr5PW1sbbt26ddeM0+kEMHjU6nZ6vR6hoaGqBxEREfmneyqEenp68Jvf/AbR0dGIi4uDyWTCkSNHlPbe3l4cO3YMSUlJAIAZM2Zg7NixqkxTUxMcDoeSmT17NlwuF06fPq1kTp06BZfLpco4HA40NTUpmfLycuj1esyYMUPJHD9+XLWkvry8HGazGbGxsffysYmIiMhfjGQGdn5+vlRWVsrvfvc7OXnypGRkZEhISIjU1dWJiMjGjRvFaDSK1WqV2tpaWbp0qURHR4vb7VZeY/ny5RITEyMVFRVy9uxZmTdvnkyfPl36+vqUzBNPPCHTpk0Tu90udrtdEhMTJSMjQ2nv6+uThIQESUtLk7Nnz0pFRYXExMRIXl6ekmlvb5eoqChZunSp1NbWitVqldDQUCkuLh7JR+aqMSIiovvQcL+/R1QIffe735Xo6GgZO3asmM1mycrKkvPnzyvtXq9X1q1bJyaTSfR6vTz66KNSW1ureo2uri7Jy8uT8PBwMRgMkpGRIfX19apMa2urLFu2TEJCQiQkJESWLVsmbW1tqsy1a9ckPT1dDAaDhIeHS15enmqpvIjIuXPnxGKxiF6vF5PJJIWFhSNaOi/CQoiIiOh+NNzvb50It1q+G7fbDaPRCJfLxflCRERE94nhfn/zrDEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIURERESaxUKIiIiINGuMrztAROQLHo8HNpsNTU1NiI6OhsViQWBgoK+7RUSjjCNCRKQ5VqsV8fHxSE1NRU5ODlJTUxEfHw+r1errrhHRKGMhRESaYrVakZ2djcTERNjtdnR0dMButyMxMRHZ2dkshog0hkdsDIFHbBD5D4/Hg/j4eCQmJmL//v0ICPjj34JerxeZmZlwOBy4fPkyb5MR3ed4xAYR0QA2mw11dXVYu3YtRASVlZXYs2cPKisrISIoKCjA1atXYbPZfN1VIholnCxNRJrR1NQEALhy5QqWLl2Kuro6pS02NhavvfaaKkdE/o8jQkSkGdHR0QCA3NzcO84Rys3NVeWIyP9xjtAQOEeIyH/09vYiODgYEyZMwPXr1zFmzB8Hxfv6+hATE4PW1lZ0dnYiKCjIhz0lonvFOUJERAOcOHECfX19aGlpQVZWlmpEKCsrCy0tLejr68OJEyd83VUiGiUshIhIM/rn/rz11luora1FUlISQkNDkZSUBIfDgbfeekuVIyL/x8nSRKQZ/XN/pk6dio8++mjQztKnT59W5YjI/3GO0BA4R4jIf3AfISLt4BwhIqIBAgMDsXnzZhw4cACZmZmqOUKZmZk4cOAAiouLWQQRaQhvjRGRpmRlZaG0tBT5+flISkpSrsfFxaG0tBRZWVk+7B0RjTbeGhsCb40R+SeePk/k34b7/c0RISLSpMDAQKSkpPi6G0TkY5wjRERERJrFQoiIiIg0i4UQERERaRYLISIiItIsFkJERESkWSyEiIiISLNYCBEREZFmsRAiIiIizeKGikSkSdxZmogAjggRkQZZrVZMnToVqampyMnJQWpqKqZOnQqr1errrhHRKGMhRESaYrVasWTJEjidTtV1p9OJJUuWsBgi0hgeujoEHrpK5D88Hg+io6Nx48YNpKen48knn4TBYEBXVxcOHTqEgwcPIjIyEo2NjbxNRnSf46GrREQDVFZW4saNG3j44YfhcDhw8OBBpW3KlCl46KGHcPHiRVRWViItLc2HPSWi0cJbY0SkGZWVlQCA3/zmN3e8NXbx4kVVjoj8HwshItIMr9er/DstLQ12ux0dHR2w2+2qEaDbc0Tk31gIEZFmhIWFAQBCQkJQWlqK7u5uvPPOO+ju7kZpaSlCQkJUOSLyf5wjRESa0dbWBgDo6OhAWFgYurq6lLb+SdO354jI/3FEiIg0IyDgj7/yenp6VG23P789R0T+jf+3E5FmWCwWAMC4ceMGtel0OuV6f46I/N89FUJFRUXQ6XRYvXq1ck1EUFhYCLPZDIPBgJSUFJw/f171cz09PVi5ciUiIiIQHByMxYsX4/r166pMW1sbcnNzYTQaYTQakZubi/b2dlWmvr4eixYtQnBwMCIiIrBq1Sr09vaqMrW1tUhOTobBYMCkSZPw6quvglsnEWlT/95A3d3diIiIQH5+PrZt24b8/HxMmDAB3d3dqhwR+b/PPUfozJkz2LVrF6ZNm6a6vmnTJmzZsgU///nP8eCDD+K1117D/Pnz8dvf/laZiLh69Wq88847KCkpwYQJE5Cfn4+MjAxUV1crv4BycnJw/fp1lJWVAQCeffZZ5Obm4p133gHw6cZo6enpmDhxIqqqqtDa2oqnnnoKIoI333wTwKebKc2fPx+pqak4c+YMLl26hKeffhrBwcHIz8//vB+diO5Tzc3Nyr87OjqwefNm5fn48ePvmCMiPyefQ0dHh3zlK1+RI0eOSHJysrz44osiIuL1esVkMsnGjRuVbHd3txiNRtm5c6eIiLS3t8vYsWOlpKREyTQ0NEhAQICUlZWJiMiFCxcEgJw8eVLJ2O12ASAXL14UEZFDhw5JQECANDQ0KJk9e/aIXq8Xl8slIiLbt28Xo9Eo3d3dSqaoqEjMZrN4vd5hfVaXyyUAlNckovvX66+/LgBkxYoVMmXKFAGgPGJjY2X58uUCQF5//XVfd5WI7tFwv78/162xF154Aenp6XjsscdU169evYrm5mYsWLBAuabX65GcnIwTJ04AAKqrq3Hr1i1Vxmw2IyEhQcnY7XYYjUbMnDlTycyaNQtGo1GVSUhIgNlsVjKPP/44enp6UF1drWSSk5Oh1+tVmcbGRtTV1d3xs/X09MDtdqseROQfJk6cCAA4efLkoFvkXq8Xp06dUuWIyP+NuBAqKSlBdXU1ioqKBrX1DydHRUWprkdFRSltzc3NCAoKGrRPx8BMZGTkoNePjIxUZQa+T1hYGIKCgu6a6X/+WUPfRUVFyrwko9GIyZMn3zFHRPefSZMmAQA+/PBD9PT0YNeuXWhsbMSuXbvQ09ODDz/8UJUjIv83ojlCH3/8MV588UWUl5ffcdVFP51Op3ouIoOuDTQwc6f8F5Hp/yvws/pTUFCANWvWKM/dbjeLISI/kZSUhDFjxiA4OBh6vR7PPvus0jZlyhQYjUZ0dnYiKSnJh70kotE0ohGh6upqOJ1OzJgxA2PGjMGYMWNw7Ngx/OQnP8GYMWM+c7TF6XQqbSaTCb29vYM2LBuYaWlpGfT+N27cUGUGvk9bWxtu3bp110z/+UIDR4r66fV6hIaGqh5E5B9OnDiBvr4+uFwufPzxx6q2+vp6uFwu9PX1Kbfgicj/jagQSktLQ21tLWpqapTHI488gmXLlqGmpgZ/8Rd/AZPJhCNHjig/09vbi2PHjil/Yc2YMQNjx45VZZqamuBwOJTM7Nmz4XK5cPr0aSVz6tQpuFwuVcbhcKCpqUnJlJeXQ6/XY8aMGUrm+PHjqiX15eXlMJvNiI2NHclHJyI/cPvvi4Gjwrdvonh7joj83L3Oyr591ZiIyMaNG8VoNIrVapXa2lpZunSpREdHi9vtVjLLly+XmJgYqaiokLNnz8q8efNk+vTp0tfXp2SeeOIJmTZtmtjtdrHb7ZKYmCgZGRlKe19fnyQkJEhaWpqcPXtWKioqJCYmRvLy8pRMe3u7REVFydKlS6W2tlasVquEhoZKcXHxsD8fV40R+Y/Dhw8LAAkPD5fu7m45evSo7N69W44ePSrd3d0SHh4uAOTw4cO+7ioR3aPhfn9/4WeN/f3f/z26urrw/PPPo62tDTNnzkR5ebmyhxAAvP766xgzZgz+5m/+Bl1dXUhLS8PPf/5z1SZmv/zlL7Fq1SplddnixYuxdetWpT0wMBAHDx7E888/jzlz5sBgMCAnJwfFxcVKxmg04siRI3jhhRfwyCOPICwsDGvWrFHNASIi7aitrQUAxMTEYOzYsUhJSVHavF4vJk2ahD/84Q+ora1VrWwlIv+lE+E2y3fjdrthNBrhcrk4X4joPrdy5UrlD6pFixahoKAACQkJcDgcKCoqUjZszcvLUzZmJaL703C/v3nWGBFpxtSpUwEAK1asQG1tLZKSkhAaGoqkpCQ4HA4sX75clSMi/8cRoSFwRIjIf/T29iI4OBgTJkzAtWvXYLfb0dTUhOjoaMyePRtTpkxBa2srOjs7ERQU5OvuEtE94IgQEdEAQUFBeOmll9DS0oIpU6bg0qVLSE5OxqVLlzBlyhS0tLTgpZdeYhFEpCFf+GRpIqI/Z5s2bQLw6aKN5557Trk+ZswY/OhHP1LaiUgbeGtsCLw1RuSfent7sX37dly5cgVTp07F888/z5EgIj8y3O9vFkJDYCFERER0/+EcISIiIqIhsBAiIiIizWIhRERERJrFQoiIiIg0i4UQERERaRb3ESIiTfJ4PLDZbMrO0haLRXXwMxFpA0eEiEhzrFYr4uPjkZqaipycHKSmpiI+Ph5Wq9XXXSOiUcZCiIg0xWq1Ijs7Gy0tLarrLS0tyM7OZjFEpDEshIhIMzweD1asWAERQVpaGux2Ozo6OmC325GWlgYRwYoVK+DxeHzdVSIaJSyEiEgzKisr4XQ6MXfuXFitVnR3d+Odd95Bd3c3rFYr5syZA6fTicrKSl93lYhGCSdLE5Fm9Bc4jz32GL7yla/g2rVrStuUKVPw9NNP4/3330dlZSXS0tJ81EsiGk0shIhIcwoLC2EwGFTXnE4n1q9f76MeEZGv8NYYEWmGxWJR/j1v3jzVHKF58+bdMUdE/o2FEBFpkk6ng4goD51O5+suEZEP8NYYEWmGzWZT/v3ee+/hwIEDyvPx48ercgsWLBjVvhGRb3BEiIg0p7CwEJGRkaprkZGR+Od//mcf9YiIfIWFEBFpRkpKCgCgoqICly9fxtGjR7F7924cPXoUly5dwnvvvafKEZH/04mI+LoTf87cbjeMRiNcLhdCQ0N93R0iugcejwdmsxlOpxPp6elYuHAhDAYDurq68O677+LgwYOIjIxEY2Mjzx0jus8N9/ubc4SISDMCAwOxY8cOLFmyBIcOHcLBgweVtv7J0jt27GARRKQhvDVGRJqj0+kwbtw41bVx48Zx5RiRBvHW2BB4a4zIf3g8HsTHxyMiIgJOpxP19fVK25e//GVERkaitbUVly9f5qgQ0X1uuN/fHBEiIs2w2Wyoq6vDBx98gOnTp6s2VJw+fTo++OADXL16VbXMnoj8GwshItKMhoYGAMDChQuxf/9+zJo1Cw888ABmzZqF/fv3Y+HChaocEfk/FkJEpBk3btwAAGRlZSEgQP3rLyAgAJmZmaocEfk/FkJEpBkTJ04EAFitVni9XlWb1+vF/v37VTki8n8shIhIMyZNmgQAKCsrQ2ZmpmqOUGZmJsrKylQ5IvJ/XDU2BK4aI/Ift68a+/3vf4+6ujqlLS4uDhMmTOCqMSI/wQ0ViYgGCAwMxObNm5GdnY309HS8/PLLys7SZWVlOHjwIEpLS1kEEWkICyEi0pSsrCyUlpYiPz9fdfp8XFwcSktLkZWV5cPeEdFo462xIfDWGJF/8ng8sNlsaGpqQnR0NCwWC0eCiPwIb40REd1FYGAgT5knIq4aIyIiIu1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSrBEVQjt27MC0adMQGhqK0NBQzJ49G++++67SLiIoLCyE2WyGwWBASkoKzp8/r3qNnp4erFy5EhEREQgODsbixYtx/fp1VaatrQ25ubkwGo0wGo3Izc1Fe3u7KlNfX49FixYhODgYERERWLVqFXp7e1WZ2tpaJCcnw2AwYNKkSXj11VfB3QKICPh0+XxlZSX27NmDyspKeDweX3eJiHxgRIVQTEwMNm7ciA8++AAffPAB5s2bh29/+9tKsbNp0yZs2bIFW7duxZkzZ2AymTB//nx0dHQor7F69Wrs27cPJSUlqKqqws2bN5GRkaH6JZSTk4OamhqUlZWhrKwMNTU1yM3NVdo9Hg/S09PR2dmJqqoqlJSUYO/evcjPz1cybrcb8+fPh9lsxpkzZ/Dmm2+iuLgYW7Zs+dz/sYjIP1itVsTHxyM1NRU5OTlITU1FfHw8rFarr7tGRKNN7lFYWJj8x3/8h3i9XjGZTLJx40alrbu7W4xGo+zcuVNERNrb22Xs2LFSUlKiZBoaGiQgIEDKyspEROTChQsCQE6ePKlk7Ha7AJCLFy+KiMihQ4ckICBAGhoalMyePXtEr9eLy+USEZHt27eL0WiU7u5uJVNUVCRms1m8Xu+wP5/L5RIAyusS0f1t7969otPpxGAwCADlYTAYRKfTyd69e33dRSL6Agz3+/tzzxHyeDwoKSlBZ2cnZs+ejatXr6K5uRkLFixQMnq9HsnJyThx4gQAoLq6Grdu3VJlzGYzEhISlIzdbofRaMTMmTOVzKxZs2A0GlWZhIQEmM1mJfP444+jp6cH1dXVSiY5ORl6vV6VaWxsVB20OFBPTw/cbrfqQUT+wePxYMWKFRARzJs3D9u2bcPPfvYzbNu2DfPmzYOIYMWKFbxNRqQhI95Zura2FrNnz0Z3dzceeOAB7Nu3D1/72teUIiUqKkqVj4qKwrVr1wAAzc3NCAoKQlhY2KBMc3OzkomMjBz0vpGRkarMwPcJCwtDUFCQKhMbGzvoffrb4uLi7vj5ioqKsH79+iH/OxDR/aeyshJOpxMPPfQQHA4HDh48qLRNmTIFDz30EC5evIjKykqkpaX5sKdENFpGPCL01a9+FTU1NTh58iRWrFiBp556ChcuXFDadTqdKi8ig64NNDBzp/wXkZH/myh9t/4UFBTA5XIpj48//viufSei+0dlZSUA4OLFi5g2bRrsdjs6Ojpgt9sxbdo0XLx4UZUjIv834kIoKCgI8fHxeOSRR1BUVITp06fjjTfegMlkAgBlRKaf0+lURmJMJhN6e3vR1tZ210xLS8ug971x44YqM/B92tracOvWrbtmnE4ngMGjVrfT6/XKqrj+BxH5B6/XC+DT2+2/+tWvcPLkSRQUFODkyZP41a9+hVmzZqlyROT/7nkfIRFBT08P4uLiYDKZcOTIEaWtt7cXx44dQ1JSEgBgxowZGDt2rCrT1NQEh8OhZGbPng2Xy4XTp08rmVOnTsHlcqkyDocDTU1NSqa8vBx6vR4zZsxQMsePH1ctqS8vL4fZbB50y4yItGHChAkAgCtXruCBBx7ASy+9hK1bt+Kll17CAw88gI8++kiVIyINGMkM7IKCAjl+/LhcvXpVzp07J2vXrpWAgAApLy8XEZGNGzeK0WgUq9UqtbW1snTpUomOjha32628xvLlyyUmJkYqKirk7NmzMm/ePJk+fbr09fUpmSeeeEKmTZsmdrtd7Ha7JCYmSkZGhtLe19cnCQkJkpaWJmfPnpWKigqJiYmRvLw8JdPe3i5RUVGydOlSqa2tFavVKqGhoVJcXDySj8xVY0R+5K233lJWiQUFBckrr7wily9flldeeUWCgoKUtrfeesvXXSWiezTc7+8RFUI/+MEPZMqUKRIUFCQTJ06UtLQ0pQgSEfF6vbJu3ToxmUyi1+vl0UcfldraWtVrdHV1SV5enoSHh4vBYJCMjAypr69XZVpbW2XZsmUSEhIiISEhsmzZMmlra1Nlrl27Junp6WIwGCQ8PFzy8vJUS+VFRM6dOycWi0X0er2YTCYpLCwc0dJ5ERZCRP7k8OHDquXyuG35/Pjx45V/Hz582NddJaJ7NNzvb50It1q+G7fbDaPRCJfLxflCRPe5zZs34+WXX8aUKVMAQFnRCgCxsbHwer2or69HcXGxaoNWIrr/DPf7e8TL54mI7lf9e4hdu3YN48aNU7U1Nzeju7tblSMi/8dDV4lIM6ZOnar8e+A2GgEBAXfMEZF/462xIfDWGJH/6Orqwvjx4xEUFIT29nacOnUKTU1NiI6OxsyZM/GlL30Jvb29+OSTT2AwGHzdXSK6B8P9/uaIEBFpxqlTpwB8urVHXFwcLl26hOTkZFy6dAlxcXHKdhv9OSLyfyyEiEgz+vcee/HFF9Ha2ornnnsOkyZNwnPPPYfW1la8+OKLqhwR+T8WQkSkGdHR0QCA733ve+js7MTrr7+OvLw8vP766+js7MR3v/tdVY6I/B8LISLSDIvFgtjYWGzYsAE6nQ5f//rXkZSUhK9//evQ6XQoKipCXFwcLBaLr7tKRKOEy+eJSDMCAwOxefNmLFmyBEajEV1dXUqbwWBAV1cX9u7di8DAQB/2kohGE0eEiEiT+vcM+qznRKQNXD4/BC6fJ/IfHo8HZrMZTqcT6enpePLJJ5WRoEOHDuHgwYOIjIxEY2MjR4WI7nPcWZqIaIDKyko4nU7MnTsXb7/9tmoTxeXLl+PRRx/F+++/j8rKSqSlpfmwp0Q0WnhrjIg0o7KyEgCwfv16VREEfLqzdGFhoSpHRP6PI0JEpEkejwc2m03ZWZorxYi0iYUQEWlGSkoKXnvtNeTl5eGTTz5RnT4/ZcoU5ViNlJQUH/WQiEYbb40RkWakpKQgNDQUv/nNb9Dd3Y1du3ahsbERu3btQnd3Ny5evIjQ0FAWQkQawhEhItKUcePGwe12w+1249lnn1Wujx8/XmknIu3giBARaYbNZoPT6URRUREiIyNVbZGRkdiwYQOcTidsNpuPekhEo42FEBFpRv9hqnl5ebhy5QqOHj2K3bt34+jRo/joo4+Ql5enyhGR/+OtMSLSjP7DVB0OB2bNmjVoLpDD4VDliMj/cUSIiDTj9kNXvV6vqs3r9fLQVSINYiFERJrRf+jqgQMHkJmZCbvdjo6ODtjtdmRmZuLAgQMoLi7m8RpEGsJbY0SkKVlZWSgtLUV+fj6SkpKU63FxcSgtLUVWVpYPe0dEo42Hrg6Bh64S+ac77SzNkSAi/8FDV4mI7iIwMJAbJxIR5wgRERGRdrEQIiIiIs3irTEi0iTOESIigCNCRKRBVqsV8fHxSE1NRU5ODlJTUxEfHw+r1errrhHRKGMhRESaYrVakZ2djZaWFtX1lpYWZGdnsxgi0hgWQkSkGR6PBytWrICIIC0tTbWhYlpaGkQEK1asgMfj8XVXiWiUsBAiIs2orKyE0+nE3Llz8etf/xqzZs3CAw88gFmzZuHXv/415syZA6fTicrKSl93lYhGCQshItKM/gJn/fr1CAhQ//oLCAhAYWGhKkdE/o+FEBEREWkWCyEi0oz+naTXrVt3x9Pn169fr8oRkf/jWWND4FljRP7D4/EgOjoaN27cQHp6OhYuXAiDwYCuri68++67OHjwICIjI9HY2Mg9hYjuczxrjIhogMDAQOzcuRNLlizBoUOHcPDgQaVNp9MBAHbs2MEiiEhDeGuMiDSJg+FEBPDW2JB4a4zIf3g8HpjNZjidTqSnp+PJJ59Ubo31jxDx1hiRf+CtMSKiAW7fR+jtt99WLaFfvnw5Hn30Ubz//vuorKxEWlqaD3tKRKOFt8aISDNu30dIRFBZWYk9e/agsrISIsJ9hIg0iCNCRKQ5NpsNzzzzDOrq6pRrsbGxeOqpp3zXKSLyCc4RGgLnCBH5j/feew+PPfYYAGDcuHHo7u5W2m5/XlFRwVtjRPe54X5/j+jWWFFREb75zW8iJCQEkZGRyMzMxG9/+1tVpn942Ww2w2AwICUlBefPn1dlenp6sHLlSkRERCA4OBiLFy/G9evXVZm2tjbk5ubCaDTCaDQiNzcX7e3tqkx9fT0WLVqE4OBgREREYNWqVejt7VVlamtrkZycDIPBgEmTJuHVV1/lahEijbJYLMoy+dDQUOzatQuNjY3YtWuX8otSp9PBYrH4sptENIpGVAgdO3YML7zwAk6ePIkjR46gr68PCxYsQGdnp5LZtGkTtmzZgq1bt+LMmTMwmUyYP38+Ojo6lMzq1auxb98+lJSUoKqqCjdv3kRGRobqxOecnBzU1NSgrKwMZWVlqKmpQW5urtLu8XiQnp6Ozs5OVFVVoaSkBHv37kV+fr6ScbvdmD9/PsxmM86cOYM333wTxcXF2LJly+f6j0VE9zebzab8IdTR0YFnn30WZrMZzz77LG7evAng0z/mbDabL7tJRKNJ7oHT6RQAcuzYMRER8Xq9YjKZZOPGjUqmu7tbjEaj7Ny5U0RE2tvbZezYsVJSUqJkGhoaJCAgQMrKykRE5MKFCwJATp48qWTsdrsAkIsXL4qIyKFDhyQgIEAaGhqUzJ49e0Sv14vL5RIRke3bt4vRaJTu7m4lU1RUJGazWbxe77A+o8vlEgDKaxLR/evHP/6xAJDCwkKZMmWKAFAesbGxsm7dOgEgP/7xj33dVSK6R8P9/r6nVWMulwsAEB4eDgC4evUqmpubsWDBAiWj1+uRnJyMEydOAACqq6tx69YtVcZsNiMhIUHJ2O12GI1GzJw5U8nMmjULRqNRlUlISIDZbFYyjz/+OHp6elBdXa1kkpOTodfrVZnGxkbVJMnb9fT0wO12qx5E5F8sFguuXLmCo0ePYvfu3Th69Cg++ugjzJ0719ddI6JR9rkLIRHBmjVrMHfuXCQkJAAAmpubAQBRUVGqbFRUlNLW3NyMoKAghIWF3TUTGRk56D0jIyNVmYHvExYWhqCgoLtm+p/3ZwYqKipS5iUZjUZMnjx5iP8SRHS/uP3QVZ1Oh5SUFCxduhQpKSnQ6XQ8dJVIgz738vm8vDycO3cOVVVVg9r6JyP2E5FB1wYamLlT/ovIyP/ND/is/hQUFGDNmjXKc7fbzWKIyE+kpKRg4sSJqKqqwuLFiwcdulpVVYXIyEgWQkQa8rkKoZUrV+Ltt9/G8ePHERMTo1w3mUwAPh1tiY6OVq47nU5lJMZkMqG3txdtbW2qUSGn04mkpCQl09LSMuh9b9y4oXqdU6dOqdrb2tpw69YtVWbgyI/T6QQweNSqn16vV91KIyL/cfuhqwcPHlQdutqPh64SacuIbo2JCPLy8mC1WvE///M/iIuLU7XHxcXBZDLhyJEjyrXe3l4cO3ZMKXJmzJiBsWPHqjJNTU1wOBxKZvbs2XC5XDh9+rSSOXXqFFwulyrjcDjQ1NSkZMrLy6HX6zFjxgwlc/z4cdWS+vLycpjNZsTGxo7koxORnxk4KjzUqDUR+amRzMBesWKFGI1GqayslKamJuXxySefKJmNGzeK0WgUq9UqtbW1snTpUomOjha3261kli9fLjExMVJRUSFnz56VefPmyfTp06Wvr0/JPPHEEzJt2jSx2+1it9slMTFRMjIylPa+vj5JSEiQtLQ0OXv2rFRUVEhMTIzk5eUpmfb2domKipKlS5dKbW2tWK1WCQ0NleLi4mF/Zq4aI/IffX19MnHiRAEg6enpsm3bNvnZz34m27Ztk/T0dAEgkZGRqt9FRHR/Gu7394gKIdy21PT2x3/+538qGa/XK+vWrROTySR6vV4effRRqa2tVb1OV1eX5OXlSXh4uBgMBsnIyJD6+npVprW1VZYtWyYhISESEhIiy5Ytk7a2NlXm2rVrkp6eLgaDQcLDwyUvL0+1VF5E5Ny5c2KxWESv14vJZJLCwsJhL50XYSFE5E8qKioEgMydO1c8Ho+qzePxyNy5cwWAVFRU+KiHRPRFGe73N4/YGAKP2CDyH//0T/+E1157De+99x7mzZs3qL2iogLz58/Hj3/8Y/zLv/yLD3pIRF+UP8kRG0RERET+hIUQEWnG7fsIeb1eVZvX60VhYaEqR0T+j4UQEWlGSkoKIiMjUVVVhW9/+9uw2+3o6OiA3W7Ht7/9bbz//vvcR4hIYz73hopERPebwMBA7NixA9nZ2Xjvvfdw4MABpW38+PHQ6XTcR4hIYzgiRESakpWVhZdfflm1vxjw6Z5nL7/8MrKysnzUMyLyBY4IEZGmWK1WFBcXIz09fdARG8XFxZg1axaLISIN4fL5IXD5PJH/8Hg8iI+PR2JiIvbv34+AgD8Oinu9XmRmZsLhcODy5cu8PUZ0n+PyeSKiAWw2G+rq6rB27VpVEQQAAQEBKCgowNWrV2Gz2XzUQyIabSyEiEgz+s8mTEhIuGN7//XbzzAkIv/GQoiINCM6OhoA4HA44PF4UFlZiT179qCyshIejwcOh0OVIyL/xzlCQ+AcISL/0T9HKCIiAr///e9RV1entMXGxiIiIgKtra2cI0TkBzhHiIhogMDAQHznO9/BBx98gK6uLuzatQuNjY3YtWsXurq68MEHHyA7O5tFEJGGcERoCBwRIvIft48I3bhxA9euXVPaOCJE5F+G+/3NfYSISDP6V43t2bMH3/zmN2Gz2dDU1ITo6GhYLBacPn0aSUlJsNlsPGaDSCNYCBGRZty+aiwwMHBQscNVY0TawzlCRKQZt68auxOuGiPSHhZCRKQZFosFsbGx2LBhA7xer6rN6/WiqKgIcXFxsFgsPuohEY02FkJEpBmBgYHYvHkzDhw4gMzMTNjtdnR0dMButyMzMxMHDhxAcXExJ0oTaQjnCBGRpmRlZaG0tBT5+flISkpSrsfFxaG0tJQHrhJpDJfPD4HL54n8U29vL7Zv344rV65g6tSpeP755xEUFOTrbhHRF4TL54mIPoPVakV+fr5qZ+k33ngDmzdv5ogQkcZwjhARaYrVakV2djYSExNVc4QSExORnZ0Nq9Xq6y4S0SjirbEh8NYYkf/o31k6MTER+/fvR0DAH/8W9Hq9yMzMhMPh4M7SRH6AZ40REQ3Qv7P02rVrVUUQAAQEBKCgoABXr16FzWbzUQ+JaLSxECIizbh9Z+k74c7SRNrDydJEpBm37yz9V3/1V4NWjXFnaSLt4RyhIXCOEJH/6J8jFBgYiLq6Ong8HqUtMDAQsbGx8Hq9nCNE5Ac4R4iIaIDAwEBMnz4dV65cQWBgIF555RVcvnwZr7zyCgIDA3HlyhVMmzaNRRCRhnBEaAgcESLyH729vQgODkZwcDDCwsJU+wjFxcXhD3/4Azo7O9HZ2cnNFYnucxwRIiIaYPv27ejr60NxcTE++ugjHD16FLt378bRo0dx+fJlbNq0CX19fdi+fbuvu0pEo4STpYlIM65cuQIAyMjIQGBgIFJSUlTtGRkZqhwR+T+OCBGRZkydOhUAcODAgTu291/vzxGR/+McoSFwjhCR/+ifIzRhwgRcv34dY8b8cVC8r68PMTExaG1t5RwhIj/AOUJERAMEBQXhpZdeQktLC2JiYrBr1y40NjZi165diImJQUtLC1566SUWQUQawjlCRKQpmzZtAgC8/vrreO6555TrY8aMwY9+9COlnYi0gbfGhsBbY0T+qbe3d9DO0hwJIvIfw/3+ZiE0BBZCRERE95/hfn/z1hgRaZLH44HNZkNTUxOio6NhsVi4ozSRBnGyNBFpjtVqRXx8PFJTU5GTk4PU1FTEx8fDarX6umtENMpYCBGRplitVmRnZyMxMRF2ux0dHR2w2+1ITExEdnY2iyEijeEcoSFwjhCR/+g/fT4xMRF79+7F+++/r9wamzNnDpYsWQKHw8HT54n8APcRIiIawGazoa6uDklJSXjwwQdVt8YefPBBzJ49G1evXoXNZvN1V4lolIy4EDp+/DgWLVoEs9kMnU6H/fv3q9pFBIWFhTCbzTAYDEhJScH58+dVmZ6eHqxcuRIREREIDg7G4sWLcf36dVWmra0Nubm5MBqNMBqNyM3NRXt7uypTX1+PRYsWITg4GBEREVi1ahV6e3tVmdraWiQnJ8NgMGDSpEl49dVXwUEwIm1qamoCABQUFCAhIQHbtm3Dz372M2zbtg0JCQlYu3atKkdE/m/EhVBnZyemT5+OrVu33rF906ZN2LJlC7Zu3YozZ87AZDJh/vz56OjoUDKrV6/Gvn37UFJSgqqqKty8eRMZGRnweDxKJicnBzU1NSgrK0NZWRlqamqQm5urtHs8HqSnp6OzsxNVVVUoKSnB3r17kZ+fr2Tcbjfmz58Ps9mMM2fO4M0330RxcTG2bNky0o9NRH4gMjISAPDQQw+htrYWL7zwAn7wgx/ghRdeQG1tLR566CFVjog0QO4BANm3b5/y3Ov1islkko0bNyrXuru7xWg0ys6dO0VEpL29XcaOHSslJSVKpqGhQQICAqSsrExERC5cuCAA5OTJk0rGbrcLALl48aKIiBw6dEgCAgKkoaFByezZs0f0er24XC4REdm+fbsYjUbp7u5WMkVFRWI2m8Xr9Q7rM7pcLgGgvCYR3b8qKioEgACQjIwMsdvt0tHRIXa7XTIyMpS2iooKX3eViO7RcL+/v9A5QlevXkVzczMWLFigXNPr9UhOTsaJEycAANXV1bh165YqYzabkZCQoGTsdjuMRiNmzpypZGbNmgWj0ajKJCQkwGw2K5nHH38cPT09qK6uVjLJycnQ6/WqTGNjI+rq6u74GXp6euB2u1UPIvIPzc3Nyr9FBNXV1fjVr36F6upq1S3z23NE5N++0A0V+395REVFqa5HRUXh2rVrSiYoKAhhYWGDMv0/39zcfMeh6cjISFVm4PuEhYUhKChIlYmNjR30Pv1tcXFxg96jqKgI69evH9bnJaL7y40bNwB8+gfR4cOHcfDgQaVtzJgxmD9/Po4cOaLkiMj//Ul2ltbpdKrnIjLo2kADM3fKfxGZ/r/6Pqs/BQUFWLNmjfLc7XZj8uTJd+07Ed0fJk6cCAA4fPgw0tPT8eSTT8JgMKCrqwuHDh1SCqP+HBH5vy/01pjJZAIweFjZ6XQqIzEmkwm9vb1oa2u7a6alpWXQ69+4cUOVGfg+bW1tuHXr1l0zTqcTwOBRq356vR6hoaGqBxH5h/7fUf1ERHncLUdE/usLLYTi4uJgMplw5MgR5Vpvby+OHTuGpKQkAMCMGTMwduxYVaapqQkOh0PJzJ49Gy6XC6dPn1Yyp06dgsvlUmUcDodqmWt5eTn0ej1mzJihZI4fP65aUl9eXg6z2TzolhkRacekSZNQVlaGvLw8PPPMM8jLy0NZWRkmTZrk664R0SgbcSF08+ZN1NTUoKamBsCnE6RrampQX18PnU6H1atXY8OGDdi3bx8cDgeefvppjB8/Hjk5OQAAo9GIZ555Bvn5+Xjvvffw4Ycf4vvf/z4SExPx2GOPAQAefvhhPPHEE/jhD3+IkydP4uTJk/jhD3+IjIwMfPWrXwUALFiwAF/72teQm5uLDz/8EO+99x5efvll/PCHP1RGcXJycqDX6/H000/D4XBg37592LBhA9asWTPkrToi8j/9I8INDQ3wer2qNq/Xi4aGBlWOiDRgpMvRjh49qiwxvf3x1FNPicinS+jXrVsnJpNJ9Hq9PProo1JbW6t6ja6uLsnLy5Pw8HAxGAySkZEh9fX1qkxra6ssW7ZMQkJCJCQkRJYtWyZtbW2qzLVr1yQ9PV0MBoOEh4dLXl6eaqm8iMi5c+fEYrGIXq8Xk8kkhYWFw146L8Ll80T+5Pbl8waDQfU77PbnXD5PdP8b7vc3zxobAs8aI/If5eXlePzxx/HAAw8gPDwc9fX1StuXv/xl/OEPf8DNmzdx+PBh1RYfRHT/4VljREQD9J8hdvPmTfT09GDXrl1obGzErl270NPTg5s3b6pyROT//iTL54mI/hz1zwt68MEH0dvbi2effVZpi4uLw4MPPohLly4Nmj9ERP6LhRARaUZ4eDgAYNy4cfjf//1f7Ny5E1euXMHUqVOxfPlyfOtb31LliMj/sRAiIs3o3x/o3LlzCA8PR1dXl9K2du1a5Tn3ESLSDs4RIiLNuH2foJ6eHlXb7fuNcT8hIu1gIUREmpGUlIQxY8bAaDQiJiZG1RYTEwOj0YgxY8YoG7cSkf/jrTEi0owTJ06gr68PLpcLc+fORWZmJrq7uzFu3DhcuXJFOWvsxIkTSElJ8W1niWhUsBAiIs3oP5LnxRdfxLZt29DX16e0jRkzBi+++CLeeOMN1dE9ROTfWAgRkWZER0cDAH7yk58gPT0dCxcuVE6ff/fdd/GTn/xElSMi/8edpYfAnaWJ/Edvby+Cg4MxYcIEXLt2DXa7HU1NTYiOjsbs2bMxZcoUtLa2orOzE0FBQb7uLhHdg+F+f3NEiIg0o3+OUEtLC8LCwlTL5/tHhvpznCNEpA1cNUZEmtE/90en0w1q0+l0ynXOESLSDhZCRKQZkZGRAIA5c+bA5XLh6NGj2L17N44ePYr29nbMmTNHlSMi/8dbY0SkSYGBgarbX16vF5wySaQ9HBEiIs1wOp0AgKqqKmRmZsJut6OjowN2ux2ZmZl4//33VTki8n8shIhIM/qXxRcVFaG2thZJSUkIDQ1FUlISHA4HNmzYoMoRkf/jrTEi0gyLxYLY2FicOHECly5dwvvvv68sn58zZw6WLFmCuLg4WCwWX3eViEYJR4SISDMCAwOxefNmHDhwAEuWLIFer0dGRgb0ej2WLFmCAwcOoLi4GIGBgb7uKhGNEo4IEZGmZGVlobS0FPn5+arDVePi4lBaWoqsrCwf9o6IRht3lh4Cd5Ym8k8ejwc2m025NWaxWDgSRORHuLM0EdFdDFw+T0TaxDlCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIURERESaxUKIiIiINIuFEBEREWkWCyEiIiLSLBZCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIUREmjRz5kzodDrlMXPmTF93iYh8QBOF0Pbt2xEXF4dx48ZhxowZsNlsvu4SEfmQTqfD6dOnVddOnz4NnU7nox4Rka/4fSH03//931i9ejX+8R//ER9++CEsFgsWLlyI+vp6X3eNiHxgqGKHxRCRtvh9IbRlyxY888wz+Lu/+zs8/PDD+Ld/+zdMnjwZO3bs8HXXiGiU3X77KycnByKiPHJycu6YIyL/NsbXHfhT6u3tRXV1NV555RXV9QULFuDEiRN3/Jmenh709PQoz91u95+0j0Ra8fumj2Hb9//u+XU++aQTV6787nP97K36D/AN06d//301tBuvrliitH01FErbrfoPVG0jMXXqX2D8+ODP9bP9Jk0y41sLvw8Ejb+n1yGiofl1IfT73/8eHo8HUVFRqutRUVFobm6+488UFRVh/fr1o9E9Ik2x7ft/+Gvn61/Mi0UNHbmTf37ugdueVYy4fVhu/t/jXjiBqxMjEZeUeY8vRERD8etCqN/Ae/4i8pnzAAoKCrBmzRrludvtxuTJk/+k/SPSAstfP4N9++79de5lRGj//v3KvzMzM0fcPhxf2IjQIwvu6TWIaHj8uhCKiIhAYGDgoNEfp9M5aJSon16vh16vH43uEWlKRPRk/PXzhT7tw8GzM5XVYg+7x+GXv/yl0rZs2TJ82OwFAHzrW9/CP+/Y65M+EtHo8uvJ0kFBQZgxYwaOHDmiun7kyBEkJSX5qFdE5CunTp1S/r17927VPkK7d+++Y46I/JtfjwgBwJo1a5Cbm4tHHnkEs2fPxq5du1BfX4/ly5f7umtE5AN3uzXe305E2uH3hdB3v/tdtLa24tVXX0VTUxMSEhJw6NAhTJkyxdddIyIfERHMnDlTtanit771LY4EEWmQTvjnz1253W4YjUa4XC6Ehob6ujtEREQ0DMP9/vbrOUJEREREd8NCiIiIiDSLhRARERFpFgshIiIi0iwWQkRERKRZLISIiIhIs1gIERERkWaxECIiIiLNYiFEREREmuX3R2zcq/6Nt91ut497QkRERMPV/7091AEaLISG0NHRAQCYPHmyj3tCREREI9XR0QGj0fiZ7TxrbAherxeNjY0ICQm564nVRHT/cbvdmDx5Mj7++GOeJUjkZ0QEHR0dMJvNCAj47JlALISISLN4qDIRcbI0ERERaRYLISIiItIsFkJEpFl6vR7r1q2DXq/3dVeIyEc4R4iIiIg0iyNCREREpFkshIiIiEizWAgRERGRZrEQIiIiIs1iIUREmnP8+HEsWrQIZrMZOp0O+/fv93WXiMhHWAgRkeZ0dnZi+vTp2Lp1q6+7QkQ+xkNXiUhzFi5ciIULF/q6G0T0Z4AjQkRERKRZLISIiIhIs1gIERERkWaxECIiIiLNYiFEREREmsVVY0SkOTdv3sRHH32kPL969SpqamoQHh6OL3/5yz7sGRGNNp4+T0SaU1lZidTU1EHXn3rqKfz85z8f/Q4Rkc+wECIiIiLN4hwhIiIi0iwWQkRERKRZLISIiIhIs1gIERERkWaxECIiIiLNYiFEREREmsVCiIiIiDSLhRARERFpFgshIiIi0iwWQkRERKRZLISIiIhIs1gIERERkWb9f6PviXhxacWiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(data['feature_116'].dropna())\t\t\t\t#数据集\n",
    "plt.boxplot(x)    \t\t\t\t#垂直显示箱线图\n",
    "plt.show()\t\t\t\t\t\t#显示该图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count     10000\n",
       " unique        2\n",
       " top       False\n",
       " freq       9947\n",
       " Name: feature_116, dtype: object,\n",
       " count     10000\n",
       " unique        2\n",
       " top       False\n",
       " freq       9947\n",
       " Name: feature_116, dtype: object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_116']>10000).describe(), (data['feature_116']>100).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "116属性里面有53个异常数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000\n",
       "unique        2\n",
       "top       False\n",
       "freq       9944\n",
       "Name: feature_119, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_119']>100).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，119里面有56个，那合理怀疑前面的也有这种异常大的数据存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.804220</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.157242</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>1.122944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.732584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-15.118262</td>\n",
       "      <td>0.590192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.276093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583108</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.852767</td>\n",
       "      <td>4.685032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.601408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.691250</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.907026</td>\n",
       "      <td>0.927391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.129846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.867626</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.992557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173169</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.165119</td>\n",
       "      <td>7.096296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.474665</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-6.160454</td>\n",
       "      <td>0.709718</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.189316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068687</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.600518</td>\n",
       "      <td>4.988225</td>\n",
       "      <td>7.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.187483</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.279090</td>\n",
       "      <td>0.143929</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435415</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>1.328274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.707751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.814346</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.580825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334893</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.237845</td>\n",
       "      <td>1.219853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.555282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.271178</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.266668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366215</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>1.428329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.565160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.022212</td>\n",
       "      <td>0.839743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.695831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561938</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>3.113039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60192.0</td>\n",
       "      <td>0.727227</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36.0</td>\n",
       "      <td>9.613106</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.449848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.728888</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.049360</td>\n",
       "      <td>0.286351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.174472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          48.0   9.804220   0.064283        6.0        5.0      211.0   \n",
       "1          45.0 -15.118262   0.590192       10.0        2.0      141.0   \n",
       "2          56.0   1.691250   0.173249        8.0        1.0      251.0   \n",
       "3          50.0   5.867626   0.004743        8.0        3.0      186.0   \n",
       "4          49.0  -6.160454   0.709718        9.0        3.0      240.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995       67.0   1.279090   0.143929       10.0        3.0      210.0   \n",
       "9996       56.0   4.814346   0.697155        6.0        6.0      267.0   \n",
       "9997       57.0  -0.271178   0.579603        8.0        5.0      168.0   \n",
       "9998       52.0  -1.022212   0.839743        8.0        1.0      242.0   \n",
       "9999       36.0   9.613106   0.680197        8.0        4.0      162.0   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0          45.0        8.0        3.0   2.711200  ...     1.157242   \n",
       "1          48.0        7.0        1.0   3.276093  ...     0.583108   \n",
       "2          47.0        6.0        1.0   1.082628  ...     0.741096   \n",
       "3          39.0        8.0        1.0   2.992557  ...     1.173169   \n",
       "4          57.0        6.0        1.0   3.189316  ...     1.068687   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9995       51.0        8.0        1.0   0.670449  ...     1.435415   \n",
       "9996       44.0        9.0        2.0   0.580825  ...     0.334893   \n",
       "9997       57.0        8.0        5.0  14.266668  ...     1.366215   \n",
       "9998       37.0       10.0        3.0   0.695831  ...     0.561938   \n",
       "9999       52.0        7.0        1.0   3.449848  ...     1.728888   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0            44.0     0.027881     1.122944          0.0         47.0   \n",
       "1            62.0     0.852767     4.685032          1.0         38.0   \n",
       "2            62.0     0.907026     0.927391          2.0         53.0   \n",
       "3            60.0     0.165119     7.096296          1.0         56.0   \n",
       "4            54.0     0.600518     4.988225          7.0         52.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995         50.0     0.607483     1.328274          4.0         49.0   \n",
       "9996         63.0     0.237845     1.219853          1.0         55.0   \n",
       "9997         45.0     0.491556     1.428329          2.0         59.0   \n",
       "9998         55.0     0.508272     3.113039          1.0      60192.0   \n",
       "9999         50.0     0.049360     0.286351          3.0         50.0   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        1.732584          2.0         52.0      0  \n",
       "1        0.601408          2.0         44.0      0  \n",
       "2        2.129846          1.0         46.0      0  \n",
       "3        0.474665          2.0         38.0      2  \n",
       "4        1.187483          2.0         38.0      2  \n",
       "...           ...          ...          ...    ...  \n",
       "9995     0.707751          1.0         52.0      1  \n",
       "9996     0.555282          4.0         52.0      3  \n",
       "9997     1.565160          2.0         41.0      0  \n",
       "9998     0.727227          3.0         65.0      0  \n",
       "9999     1.174472          1.0         54.0      0  \n",
       "\n",
       "[10000 rows x 121 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000000e+04\n",
       "mean     5.137623e+03\n",
       "std      8.306486e+04\n",
       "min      0.000000e+00\n",
       "25%      1.620000e+02\n",
       "50%      1.940000e+02\n",
       "75%      2.220000e+02\n",
       "max      2.072000e+06\n",
       "Name: feature_5, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_5']).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑对列数据的中位数确定分类方便处理异常值为边界值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "datanames = names.drop('label')\n",
    "list100 = []\n",
    "for obj in datanames:\n",
    "    if np.median(data[obj]) > 100:\n",
    "        list100.append(0)\n",
    "    elif np.median(data[obj]) <= 100 and np.median(data[obj]) > 10:\n",
    "        list100.append(1)\n",
    "    else:\n",
    "        list100.append(2)\n",
    "print(list100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "感觉这么考虑可能有点欠妥当而且工作量有点大，考虑对连续数据进行映射处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_0'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找整型列，由于数据将整型保存成float64而不是int64/32，故只能重新判断\n",
    "def judgeint(data, colnames):\n",
    "    # 如果超过95%的数据都是整数就认为是整数，并将数据处理成整数\n",
    "    jud = []\n",
    "    for obj in colnames:\n",
    "        cnt = 0\n",
    "        for i in data[obj]:\n",
    "            if i.is_integer():\n",
    "                cnt += 1\n",
    "        if cnt/len(data[obj]) > 0.95:\n",
    "            data[obj] = data[obj].astype(np.int64)\n",
    "            jud.append(1)\n",
    "        else:\n",
    "            jud.append(0)\n",
    "    return jud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "list_isint = judgeint(data, datanames)\n",
    "print(list_isint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20123\\AppData\\Local\\Temp\\ipykernel_2444\\2809947450.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[obj][i] = sigmoid(data1[obj][i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>9.999481e-01</td>\n",
       "      <td>0.391603</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610459</td>\n",
       "      <td>44</td>\n",
       "      <td>0.381456</td>\n",
       "      <td>0.158529</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.736803</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2.890462e-07</td>\n",
       "      <td>0.521319</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.584558</td>\n",
       "      <td>0.869083</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.474583</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>8.523097e-01</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>62</td>\n",
       "      <td>0.597672</td>\n",
       "      <td>0.134148</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806384</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>9.973465e-01</td>\n",
       "      <td>0.377512</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614240</td>\n",
       "      <td>60</td>\n",
       "      <td>0.414320</td>\n",
       "      <td>0.986668</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.443122</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2.240370e-03</td>\n",
       "      <td>0.551035</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589207</td>\n",
       "      <td>54</td>\n",
       "      <td>0.522302</td>\n",
       "      <td>0.899896</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.618767</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>67</td>\n",
       "      <td>7.926005e-01</td>\n",
       "      <td>0.410733</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674238</td>\n",
       "      <td>50</td>\n",
       "      <td>0.524039</td>\n",
       "      <td>0.187874</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.501146</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56</td>\n",
       "      <td>9.924297e-01</td>\n",
       "      <td>0.547925</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>267</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.104307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407791</td>\n",
       "      <td>63</td>\n",
       "      <td>0.432071</td>\n",
       "      <td>0.171888</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.463096</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57</td>\n",
       "      <td>4.477923e-01</td>\n",
       "      <td>0.518676</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658860</td>\n",
       "      <td>45</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>52</td>\n",
       "      <td>2.767523e-01</td>\n",
       "      <td>0.582946</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463550</td>\n",
       "      <td>55</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>0.579539</td>\n",
       "      <td>1</td>\n",
       "      <td>60192</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36</td>\n",
       "      <td>9.999371e-01</td>\n",
       "      <td>0.543721</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735146</td>\n",
       "      <td>50</td>\n",
       "      <td>0.386537</td>\n",
       "      <td>0.075452</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.615693</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0     feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0            48  9.999481e-01   0.391603          6          5        211   \n",
       "1            45  2.890462e-07   0.521319         10          2        141   \n",
       "2            56  8.523097e-01   0.417848          8          1        251   \n",
       "3            50  9.973465e-01   0.377512          8          3        186   \n",
       "4            49  2.240370e-03   0.551035          9          3        240   \n",
       "...         ...           ...        ...        ...        ...        ...   \n",
       "9995         67  7.926005e-01   0.410733         10          3        210   \n",
       "9996         56  9.924297e-01   0.547925          6          6        267   \n",
       "9997         57  4.477923e-01   0.518676          8          5        168   \n",
       "9998         52  2.767523e-01   0.582946          8          1        242   \n",
       "9999         36  9.999371e-01   0.543721          8          4        162   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0            45          8          3   0.495028  ...     0.610459   \n",
       "1            48          7          1   0.632976  ...     0.468818   \n",
       "2            47          6          1   0.161317  ...     0.508274   \n",
       "3            39          8          1   0.564997  ...     0.614240   \n",
       "4            57          6          1   0.612594  ...     0.589207   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9995         51          8          1   0.112982  ...     0.674238   \n",
       "9996         44          9          2   0.104307  ...     0.407791   \n",
       "9997         57          8          5   0.999990  ...     0.658860   \n",
       "9998         37         10          3   0.115551  ...     0.463550   \n",
       "9999         52          7          1   0.672334  ...     0.735146   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0              44     0.381456     0.158529            0           47   \n",
       "1              62     0.584558     0.869083            1           38   \n",
       "2              62     0.597672     0.134148            2           53   \n",
       "3              60     0.414320     0.986668            1           56   \n",
       "4              54     0.522302     0.899896            7           52   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995           50     0.524039     0.187874            4           49   \n",
       "9996           63     0.432071     0.171888            1           55   \n",
       "9997           45     0.495076     0.203619            2           59   \n",
       "9998           55     0.499255     0.579539            1        60192   \n",
       "9999           50     0.386537     0.075452            3           50   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        0.736803            2           52      0  \n",
       "1        0.474583            2           44      0  \n",
       "2        0.806384            1           46      0  \n",
       "3        0.443122            2           38      2  \n",
       "4        0.618767            2           38      2  \n",
       "...           ...          ...          ...    ...  \n",
       "9995     0.501146            1           52      1  \n",
       "9996     0.463096            4           52      3  \n",
       "9997     0.703077            2           41      0  \n",
       "9998     0.506015            3           65      0  \n",
       "9999     0.615693            1           54      0  \n",
       "\n",
       "[10000 rows x 121 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对float的列进行预处理\n",
    "data_float_names = data.select_dtypes(include=float).columns\n",
    "data1 = data.copy(deep=True)\n",
    "def sigmoid(X):\n",
    "    if X >= 0:\n",
    "        return 1.0 / (1 + np.exp(-X))\n",
    "    else:   # 防止上溢\n",
    "        return np.exp(X)/(np.exp(X)+1)\n",
    "# 考虑到平均数由异常值的影响很大，掐头去尾取平均数和取中位数区别不大，取中位数来减\n",
    "for obj in data_float_names:\n",
    "    med = np.median(data1[obj])\n",
    "    data1[obj] = data1[obj]-med\n",
    "    for i in range(len(data1[obj])):\n",
    "        data1[obj][i] = sigmoid(data1[obj][i])\n",
    "    \n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20123\\AppData\\Local\\Temp\\ipykernel_2444\\3499660496.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[obj][data2[obj]>np.percentile(data2[obj], 95)] = np.percentile(data2[obj], 95)\n",
      "C:\\Users\\20123\\AppData\\Local\\Temp\\ipykernel_2444\\3499660496.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data2[obj][data2[obj]<np.percentile(data2[obj], 5)] = np.percentile(data2[obj], 5)\n"
     ]
    }
   ],
   "source": [
    "# 接下来处理整型的部分\n",
    "data2 = data1.copy(deep=True)\n",
    "data_int_names = data.select_dtypes(include=int).columns.drop('label')\n",
    "\n",
    "# 如果出现异常数据就用5%和95%的分位数取取边界值\n",
    "for obj in data_int_names:\n",
    "    # 肉眼观察最大值都大于0\n",
    "    if (max(data2[obj])>=0 and np.percentile(data2[obj], 95)>=0) and max(data2[obj]) > np.percentile(data2[obj], 95)*100:\n",
    "        data2[obj][data2[obj]>np.percentile(data2[obj], 95)] = np.percentile(data2[obj], 95)\n",
    "    # 最小值分类处理\n",
    "    if (min(data2[obj])>=0 and np.percentile(data2[obj], 5)>=0) and np.percentile(data2[obj], 5)-min(data2[obj]) > np.percentile(data2[obj], 95)/100:\n",
    "        data2[obj][data2[obj]<np.percentile(data2[obj], 5)] = np.percentile(data2[obj], 5)\n",
    "    if (min(data2[obj])<0 and np.percentile(data2[obj], 5)>=0) and np.percentile(data2[obj], 5)+min(data2[obj]) < min(data2[obj])/100:\n",
    "        data2[obj][data2[obj]<np.percentile(data2[obj], 5)] = np.percentile(data2[obj], 5)\n",
    "    if (min(data2[obj])<0 and np.percentile(data2[obj], 5)<0) and np.abs(np.percentile(data2[obj], 5)-min(data2[obj])) > np.abs(min(data2[obj])/100):\n",
    "        data2[obj][data2[obj]<np.percentile(data2[obj], 5)] = np.percentile(data2[obj], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>9.999481e-01</td>\n",
       "      <td>0.391603</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.495028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610459</td>\n",
       "      <td>44</td>\n",
       "      <td>0.381456</td>\n",
       "      <td>0.158529</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0.736803</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2.890462e-07</td>\n",
       "      <td>0.521319</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.584558</td>\n",
       "      <td>0.869083</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0.474583</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>8.523097e-01</td>\n",
       "      <td>0.417848</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>249</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508274</td>\n",
       "      <td>62</td>\n",
       "      <td>0.597672</td>\n",
       "      <td>0.134148</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>0.806384</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>9.973465e-01</td>\n",
       "      <td>0.377512</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>186</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.564997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.614240</td>\n",
       "      <td>60</td>\n",
       "      <td>0.414320</td>\n",
       "      <td>0.986668</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0.443122</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>2.240370e-03</td>\n",
       "      <td>0.551035</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>240</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.612594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589207</td>\n",
       "      <td>54</td>\n",
       "      <td>0.522302</td>\n",
       "      <td>0.899896</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>0.618767</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>62</td>\n",
       "      <td>7.926005e-01</td>\n",
       "      <td>0.410733</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674238</td>\n",
       "      <td>50</td>\n",
       "      <td>0.524039</td>\n",
       "      <td>0.187874</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>0.501146</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56</td>\n",
       "      <td>9.924297e-01</td>\n",
       "      <td>0.547925</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>249</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.104307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407791</td>\n",
       "      <td>62</td>\n",
       "      <td>0.432071</td>\n",
       "      <td>0.171888</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>0.463096</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57</td>\n",
       "      <td>4.477923e-01</td>\n",
       "      <td>0.518676</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>168</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658860</td>\n",
       "      <td>45</td>\n",
       "      <td>0.495076</td>\n",
       "      <td>0.203619</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>0.703077</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>52</td>\n",
       "      <td>2.767523e-01</td>\n",
       "      <td>0.582946</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463550</td>\n",
       "      <td>55</td>\n",
       "      <td>0.499255</td>\n",
       "      <td>0.579539</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0.506015</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>39</td>\n",
       "      <td>9.999371e-01</td>\n",
       "      <td>0.543721</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>162</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.735146</td>\n",
       "      <td>50</td>\n",
       "      <td>0.386537</td>\n",
       "      <td>0.075452</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.615693</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0     feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0            48  9.999481e-01   0.391603          6          5        211   \n",
       "1            45  2.890462e-07   0.521319         10          2        141   \n",
       "2            56  8.523097e-01   0.417848          8          1        249   \n",
       "3            50  9.973465e-01   0.377512          8          3        186   \n",
       "4            49  2.240370e-03   0.551035          9          3        240   \n",
       "...         ...           ...        ...        ...        ...        ...   \n",
       "9995         62  7.926005e-01   0.410733         10          3        210   \n",
       "9996         56  9.924297e-01   0.547925          6          6        249   \n",
       "9997         57  4.477923e-01   0.518676          8          5        168   \n",
       "9998         52  2.767523e-01   0.582946          8          1        242   \n",
       "9999         39  9.999371e-01   0.543721          8          4        162   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0            45          8          3   0.495028  ...     0.610459   \n",
       "1            48          7          1   0.632976  ...     0.468818   \n",
       "2            47          6          1   0.161317  ...     0.508274   \n",
       "3            39          8          1   0.564997  ...     0.614240   \n",
       "4            57          6          1   0.612594  ...     0.589207   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9995         51          8          1   0.112982  ...     0.674238   \n",
       "9996         44          9          2   0.104307  ...     0.407791   \n",
       "9997         57          8          5   0.999990  ...     0.658860   \n",
       "9998         39         10          3   0.115551  ...     0.463550   \n",
       "9999         52          7          1   0.672334  ...     0.735146   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0              44     0.381456     0.158529            0           47   \n",
       "1              62     0.584558     0.869083            1           39   \n",
       "2              62     0.597672     0.134148            2           53   \n",
       "3              60     0.414320     0.986668            1           56   \n",
       "4              54     0.522302     0.899896            5           52   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995           50     0.524039     0.187874            4           49   \n",
       "9996           62     0.432071     0.171888            1           55   \n",
       "9997           45     0.495076     0.203619            2           59   \n",
       "9998           55     0.499255     0.579539            1           62   \n",
       "9999           50     0.386537     0.075452            3           50   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        0.736803            2           52      0  \n",
       "1        0.474583            2           44      0  \n",
       "2        0.806384            1           46      0  \n",
       "3        0.443122            2           39      2  \n",
       "4        0.618767            2           39      2  \n",
       "...           ...          ...          ...    ...  \n",
       "9995     0.501146            1           52      1  \n",
       "9996     0.463096            4           52      3  \n",
       "9997     0.703077            2           41      0  \n",
       "9998     0.506015            3           62      0  \n",
       "9999     0.615693            1           54      0  \n",
       "\n",
       "[10000 rows x 121 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean       191.046800\n",
       "std         37.124286\n",
       "min        121.000000\n",
       "25%        162.000000\n",
       "50%        194.000000\n",
       "75%        222.000000\n",
       "max        249.000000\n",
       "Name: feature_5, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data2['feature_5']).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来不错，预处理到这里就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练测试数据集\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(46)\n",
    "    shuffled_indices = np.random.permutation(len(data))  # 生成和原数据等长的无序索引\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train,test = split_train_test(data2, 0.1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = train[datanames],test[datanames]\n",
    "y_train,y_test = train['label'],test['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多分类逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegresion(object):\n",
    "    def __init__(self,max_iter=1000,learning_rate=0.01):\n",
    "        self.w = None\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def softmax(self, a):\n",
    "        # 处理一下溢出\n",
    "        c = np.max(a)\n",
    "        exp_a = np.exp(a-c)#溢出对策\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        y = exp_a/sum_exp_a\n",
    "        return y\n",
    "\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        self.n_classes = len(Y)\n",
    "        W = np.zeros((np.size(X, 1), self.n_classes))\n",
    "        t0 = time.time()\n",
    "        # for _ in tqdm(range(self.max_iter), desc='Processing'):\n",
    "        for _ in range(self.max_iter):\n",
    "            W_prev = np.copy(W)\n",
    "            Y_hat = self.softmax(X @ W)\n",
    "            grad = X.T @ (Y_hat - Y)\n",
    "            W -= self.learning_rate * grad\n",
    "            if np.allclose(W, W_prev):\n",
    "                t1 = time.time()\n",
    "                print()\n",
    "                break\n",
    "            t1 = time.time()\n",
    "        self.w = W\n",
    "        print(\"一共用时：\"+str(t1-t0)+\"s\")\n",
    "\n",
    "    def predict_prob(self,X):\n",
    "        X = np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        pred_y = self.softmax(X @ self.w)\n",
    "        return pred_y\n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_prob(X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共用时：144.49014043807983s\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegresion(max_iter=10)\n",
    "model.fit(np.array(X_train), np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred,test):\n",
    "    cnt = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == test[i]:\n",
    "            cnt += 1\n",
    "    return cnt/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.249"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "acc(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节点\n",
    "class Node(object):\n",
    "    def __init__(self, feature_index=None, threshold=None, value=None, left_tree=None, right_tree=None):\n",
    "        self.feature_index = feature_index  # 特征下标\n",
    "        self.threshold = threshold          # 划分临界点\n",
    "        self.value = value                  # 叶节点权重(只有叶节点有)\n",
    "        self.left_tree = left_tree          # 左子树：小于临界值\n",
    "        self.right_tree = right_tree        # 右子树：大于临界值\n",
    "\n",
    "\n",
    "# 参数说明：最小划分样本数，最小划分增益，最大深度，gamma,lambda\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, min_samples=5, min_split_gain=1e-7, max_depth=4, gamma=0, lam=1):\n",
    "        self.min_samples = min_samples\n",
    "        self.min_split_gain = min_split_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.root = None\n",
    "\n",
    "    def gradient(self, y, y_pre):\n",
    "        \"一阶导\"\n",
    "        return -2*(y - y_pre)\n",
    "\n",
    "    def hess(self, y, y_pre):\n",
    "        \"二阶导\"\n",
    "        return 2*np.ones_like(y)\n",
    "\n",
    "    def split(self, y):\n",
    "        \"传入回归树的 y 有2列，第一列为真实值，第二列为预测值\"\n",
    "        y_true = y[:,:1]\n",
    "        y_pre = y[:,1:]\n",
    "        return y_true, y_pre\n",
    "\n",
    "    def obj(self, y, y_pre, gamma, lam):\n",
    "        \"节点得分\"\n",
    "        G = self.gradient(y, y_pre).sum()\n",
    "        H = self.hess(y, y_pre).sum()\n",
    "        return -0.5*(np.power(G,2)/(H+lam))+gamma\n",
    "\n",
    "    def gain(self, y, y_left, y_right, gamma, lam):\n",
    "        \"收益\"\n",
    "        y, y_pre = self.split(y)\n",
    "        y_left, y_left_pre = self.split(y_left)\n",
    "        y_right, y_right_pre = self.split(y_right)\n",
    "        obj_1 = self.obj(y, y_pre, gamma, lam)\n",
    "        obj_1_left = self.obj(y_left, y_left_pre, gamma, lam)\n",
    "        obj_1_right = self.obj(y_right, y_right_pre, gamma, lam)\n",
    "        obj_2 = obj_1_left + obj_1_right\n",
    "        return obj_1 - obj_2\n",
    "\n",
    "    def leaf_value(self, y, lam):\n",
    "        \"计算叶节点权重\"\n",
    "        y, y_pre = self.split(y)\n",
    "        G = self.gradient(y, y_pre).sum()\n",
    "        H = self.hess(y, y_pre).sum()\n",
    "        return -G/(H+lam)\n",
    "\n",
    "    def divide(self, X, feature_index, threshold):\n",
    "        \"按某个特征的某个值划分为左右两部分,小的在左,大的在右\"\n",
    "        split = lambda sample: sample[feature_index] < threshold\n",
    "        X_left = np.array([sample for sample in X if split(sample)])\n",
    "        X_right = np.array([sample for sample in X if not split(sample)])\n",
    "        return X_left, X_right\n",
    "\n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        \"构造决策树。注：这里的y是(m,2)维：第一列为真实值，第二列为预测值\"\n",
    "        #初始化最大收益、最好的划分及划分后的左右子树的样本集合\n",
    "        largest_gain = 0\n",
    "        # 将y合并到 X 的最后一列：方便左右子集划分\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # m, n 分别为X的行与列数\n",
    "        m, n = np.shape(X)\n",
    "        # 贪心算法求解划分的特征\n",
    "        # 划分条件：\n",
    "        # (1) 节点分配到的样本数大于阈值; \n",
    "        # (2) 当前深度不大于最大深度要求;\n",
    "        # (3) 划分后的增益大于阈值\n",
    "        if m > self.min_samples and current_depth < self.max_depth:\n",
    "            # 遍历 X 中的特征\n",
    "            for feature_index in range(n):\n",
    "                # 抽出某个特征下标 feature，合并该特征的相同数据，并对其进行由小到大的排序\n",
    "                sorted_feature_values = np.unique(X[:,feature_index])\n",
    "                # 以特征下标 feature 所在列排序后的每个值为临界点将样本划分为左右两个集合；\n",
    "                for each_value in sorted_feature_values:\n",
    "                    # 左小，右大\n",
    "                    Xy_left, Xy_right = self.divide(Xy, feature_index, each_value)\n",
    "                    # 当左右集合均不为空时进行，否则 continue\n",
    "                    if len(Xy_left) > 0 and len(Xy_right) > 0:\n",
    "                        # 左右集合所对应的标签,计算收益\n",
    "                        gain = self.gain(y, Xy_left[:,n:], Xy_right[:,n:], self.gamma, self.lam)\n",
    "                        # 记录最大收益的信息\n",
    "                        if gain > largest_gain:\n",
    "                            largest_gain = gain\n",
    "                            best_feature_index = feature_index\n",
    "                            threshold = each_value\n",
    "                            left = Xy_left\n",
    "                            right = Xy_right\n",
    "        # 划分后增益大于阈值则继续划分\n",
    "        if largest_gain > self.min_split_gain:\n",
    "            # 构造左右子树\n",
    "            left_tree = self.build_tree(left[:,:n], left[:,n:], current_depth+1)\n",
    "            right_tree = self.build_tree(right[:,:n], right[:,n:], current_depth+1)\n",
    "            return Node(feature_index=best_feature_index, threshold=threshold, left_tree=left_tree, right_tree=right_tree)\n",
    "        # 计算叶节点的权重\n",
    "        leaf_value = self.leaf_value(y, self.lam)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"开始构造树，根节点指向树根\"\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict_value(self, X, node=None):\n",
    "        \" X 是测试集的一行数据。此函数递归到叶节点，并返回叶节点的权重，作为预测值\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        # 若有节点值，则返回节点权重作为测试集的预测值\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        # 与树的当前特征节点的临界值进行比较，小则进入左子树，大则进入右子树\n",
    "        feature_value = X[node.feature_index]\n",
    "        if feature_value < node.threshold:\n",
    "            return self.predict_value(X, node.left_tree)\n",
    "        else:\n",
    "            return self.predict_value(X, node.right_tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"对于测试集，逐行进行预测\"\n",
    "        y_pre = []\n",
    "        for x in X:\n",
    "            y_pre.append(self.predict_value(x))\n",
    "        return np.array(y_pre).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 9000 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\2044963305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mY_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# np.mat(X_train).shape, np.mat(y_train).shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\2061231870.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"开始构造树，根节点指向树根\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\2061231870.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(self, X, y, current_depth)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mlargest_gain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# 将y合并到 X 的最后一列：方便左右子集划分\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mXy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;31m# m, n 分别为X的行与列数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 9000 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTree(max_depth=6)\n",
    "Y_train = np.concatenate((np.mat(y_train),np.mat(np.ones_like(y_train))),axis=0).T\n",
    "Tree.fit(np.array(X_train), np.array(Y_train))\n",
    "# np.mat(X_train).shape, np.mat(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(0, slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(0, slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\143440852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# acc(np.array(pred), np.array(y_test))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\788773861.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m                 \u001b[1;31m#  the TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5649\u001b[0m             \u001b[1;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m             \u001b[1;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (0, slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "pred = Tree.predict(X_test)\n",
    "# acc(np.array(pred), np.array(y_test))\n",
    "pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, hidden_layer_sizes=(5, 2),\n",
       "              max_iter=1000, solver='sgd', tol=1e-07)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netmodel = MPC(solver='sgd', alpha=1e-5, activation='logistic',hidden_layer_sizes=(5, 2), max_iter=1000, tol=1e-7)\n",
    "netmodel.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.255"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = netmodel.predict(np.array(X_test))\n",
    "acc(np.array(pred), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SVMModel(object):\n",
    "    \"\"\"\n",
    "    SVM model\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=1000, kernel_type='linear', C=1.0, epsilon=0.00001):\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel_func_list = {\n",
    "            'linear': self._kernel_linear,\n",
    "            'quadratic': self._kernel_quadratic,\n",
    "        }\n",
    "        self.kernel_func = self.kernel_func_list[kernel_type]\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = None\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Training model\n",
    "        :param X_train: shape = num_train, dim_feature\n",
    "        :param Y_train: shape = num_train, 1\n",
    "        :return: loss_history\n",
    "        \"\"\"\n",
    "        n, d = X_train.shape[0], X_train.shape[1]\n",
    "        self.alpha = np.zeros(n)\n",
    "        # Iteration\n",
    "        for i in tqdm(range(self.max_iter), desc='Processing'):\n",
    "            diff = self._iteration(X_train, Y_train)\n",
    "            # if i % 100 == 0:\n",
    "            #     print('Iter %r / %r, Diff %r' % (i, self.max_iter, diff))\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        return np.dot(self.w.T, X.T) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(self.w.T, X.T) + self.b).astype(int)\n",
    "\n",
    "    def _iteration(self, X_train, Y_train):\n",
    "        alpha = self.alpha\n",
    "        alpha_prev = np.copy(alpha)\n",
    "        n = alpha.shape[0]\n",
    "        for j in range(n):\n",
    "            # Find i not equal to j randomly\n",
    "            i = j\n",
    "            for _ in range(1000):\n",
    "                if i != j:\n",
    "                    break\n",
    "                i = random.randint(0, n - 1)\n",
    "            x_i, x_j, y_i, y_j = X_train[i, :], X_train[j, :], Y_train[i], Y_train[j]\n",
    "            # Define the similarity of instances. K11 + K22 - 2K12\n",
    "            k_ij = self.kernel_func(x_i, x_i) + self.kernel_func(x_j, x_j) - 2 * self.kernel_func(x_i, x_j)\n",
    "            if k_ij == 0:\n",
    "                continue\n",
    "            a_i, a_j = alpha[i], alpha[j]\n",
    "            # Calculate the boundary of alpha\n",
    "            L, H = self._cal_L_H(self.C, a_j, a_i, y_j, y_i)\n",
    "            # Calculate model parameters\n",
    "            self.w = np.dot(X_train.T, np.multiply(alpha, Y_train))\n",
    "            self.b = np.mean(Y_train - np.dot(self.w.T, X_train.T))\n",
    "            # Iterate alpha_j and alpha_i according to 'Delta W(a_j)'\n",
    "            E_i = self.predict(x_i) - y_i\n",
    "            E_j = self.predict(x_j) - y_j\n",
    "            alpha[j] = a_j + (y_j * (E_i - E_j) * 1.0) / k_ij\n",
    "            alpha[j] = min(H, max(L, alpha[j]))\n",
    "            alpha[i] = a_i + y_i * y_j * (a_j - alpha[j])\n",
    "        diff = np.linalg.norm(alpha - alpha_prev)\n",
    "        return diff\n",
    "\n",
    "    def _kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "\n",
    "    def _kernel_quadratic(self, x1, x2):\n",
    "        return np.dot(x1, x2.T) ** 2\n",
    "\n",
    "    def _cal_L_H(self, C, a_j, a_i, y_j, y_i):\n",
    "        if y_i != y_j:\n",
    "            L = max(0, a_j - a_i)\n",
    "            H = min(C, C - a_i + a_j)\n",
    "        else:\n",
    "            L = max(0, a_i + a_j - C)\n",
    "            H = min(C, a_i + a_j)\n",
    "        return L, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\2019859539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMultiClassSVM\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from utils import common\n",
    "\n",
    "class MultiClassSVM:\n",
    "    def __init__(self,C,kernel='linear',classes=None,tol=1e-3):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "\n",
    "        self.classes = classes\n",
    "        self.tol=tol\n",
    "        self.svms = []\n",
    "        self.class_num = len(classes) if classes is not None else 0\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        '''\n",
    "        :param X: N x d\n",
    "        :param y: N\n",
    "        :return:\n",
    "        '''\n",
    "        if self.classes is None:\n",
    "            self.classes = np.sort(np.unique(y))\n",
    "            self.class_num = len(self.classes)\n",
    "        for i,specified in enumerate(combinations(self.classes,2)):\n",
    "            print('SVM: %d %d' % specified)\n",
    "            data,label = common.data_filter(X,y,specified)\n",
    "            if self.kernel=='rbf':\n",
    "                sigma = auto_scale(data)\n",
    "                kernel = RBF_kernel(sigma)\n",
    "            elif self.kernel=='linear':\n",
    "                kernel = linear_kernel()\n",
    "            else:\n",
    "                raise NotImplemented()\n",
    "\n",
    "            svm = SVMModel(self.C, kernel_type=self.kernel)\n",
    "            svm.fit(data,label,tol=self.tol)\n",
    "            self.svms.append(svm)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self,X):\n",
    "        '''\n",
    "        :param X: N x d\n",
    "        :return: N\n",
    "        '''\n",
    "\n",
    "        vote_res = []\n",
    "        for svm in self.svms:\n",
    "            vote_res.append(svm.predict(X).reshape((-1,1)))\n",
    "        vote_res = np.concatenate(vote_res,axis=1).astype(np.int)\n",
    "        pred = []\n",
    "        for row in vote_res:\n",
    "            pred.append(np.argmax(np.bincount(row)))\n",
    "        pred = np.asarray(pred)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  10%|█         | 1/10 [00:10<01:35, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 / 10, Diff 2.490433516678652e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 10/10 [01:57<00:00, 11.80s/it]\n"
     ]
    }
   ],
   "source": [
    "# dim = X_train.shape\n",
    "model1 = SVMModel(max_iter=10,kernel_type='quadratic') \n",
    "loss1 = model1.fit(np.array(X_train),np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.129"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model1.predict(np.array(X_test))\n",
    "acc(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoost(object):\n",
    "    \"\"\"\n",
    "    epoch: 最大子树棵树，迭代次数\n",
    "    max_depth: 每颗子树的最大深度\n",
    "    lr: 学习率\n",
    "    Lambda: 二次正则化系数\n",
    "    gamma: 叶结点个数正则化系数\n",
    "    subsample: 样本比例\n",
    "    colsample: 特征比例\n",
    "    seed: 随机种子\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epoch=100, max_depth=6, learning_rate=0.3, gamma=0,\n",
    "                 Lambda=1.0, subsample=1.0, colsample=1.0, seed=None):\n",
    "        self.epoch = epoch\n",
    "        self.max_depth = max_depth\n",
    "        self.lr = learning_rate\n",
    "        self.Lambda = Lambda\n",
    "        self.gamma = gamma\n",
    "        self.subsample = subsample\n",
    "        self.colsample = colsample\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, ESR=None):\n",
    "        \"\"\"\n",
    "        对epoch棵树训练\n",
    "        :param X: 训练集特征\n",
    "        :param y: 训练集标签\n",
    "        :param eval_set: 验证集，用于评估泛化能力、调参以及早停机制。\n",
    "        :param ESR: Early stopping rounds，早停机制。当模型在验证集上的损失连续ESR次迭代都没有降低，则停止。\n",
    "                    并把损失最低的一次迭代次数记为最佳迭代次数best_epoch。\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        self.err = {'train': [], 'val': []}\n",
    "        self.best_epoch = self.epoch\n",
    "        self.trees = []\n",
    "        DecisionTree.set_data(X, y)\n",
    "\n",
    "        if eval_set is not None:\n",
    "            cur_val_y = np.zeros(eval_set[1].size)\n",
    "            if ESR:\n",
    "                min_val_loss = np.inf\n",
    "                non_dec_rounds = 0\n",
    "\n",
    "        # 学习第一棵树把先前输出当作0\n",
    "        cur_y = np.zeros(y.size)\n",
    "        # 开始学习\n",
    "        for i in range(self.epoch):\n",
    "            subtree = DecisionTree(self.max_depth, self.gamma, self.Lambda,\n",
    "                                   self.colsample, self.subsample, self.seed, self.lr)\n",
    "            # 根据前i-1棵子树的输出学习第i棵树\n",
    "            subtree.fit(cur_y)\n",
    "            self.trees.append(subtree)\n",
    "            # 更新预测值\n",
    "            cur_y += subtree.predict(X)\n",
    "            # 更新损失\n",
    "            self.__cal_MSE(y, cur_y, flag='train')\n",
    "            # 早停机制\n",
    "            if eval_set is not None:\n",
    "                cur_val_y += subtree.predict(eval_set[0])\n",
    "                val_loss = self.__cal_MSE(eval_set[1], cur_val_y, flag='val')\n",
    "                if ESR:\n",
    "                    if val_loss < min_val_loss:\n",
    "                        min_val_loss = val_loss\n",
    "                        non_dec_rounds = 0\n",
    "                        self.best_epoch = i + 1\n",
    "                    else:\n",
    "                        non_dec_rounds += 1\n",
    "                        if non_dec_rounds >= ESR:\n",
    "                            break\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        输出预测结果\n",
    "        :param X: 特征数组\n",
    "        :return: 预测数组\n",
    "        \"\"\"\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        for subtree in self.trees[:self.best_epoch] if self.best_epoch else self.trees:\n",
    "            pred += subtree.predict(X)\n",
    "        return pred\n",
    "\n",
    "    def __cal_MSE(self, ytrue, ypred, flag='train'):\n",
    "        \"\"\"\n",
    "        计算MSE\n",
    "        :param ytrue: 真实标签\n",
    "        :param ypred: 预测标签\n",
    "        :param flag: 损失值\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        loss = MSE(ytrue, ypred)\n",
    "        self.err[flag].append(loss)\n",
    "        return loss\n",
    "\n",
    "    def loss_curve(self):\n",
    "        plt.figure(figsize=(10, 6), dpi=80)\n",
    "        plt.title('Learning curve with lr={}'.format(self.lr))\n",
    "        plt.xlabel('epoch', fontsize=15)\n",
    "        plt.ylabel('Mean Squared Error', fontsize=15)\n",
    "        plt.xticks(fontsize=13)\n",
    "        plt.yticks(fontsize=13)\n",
    "        plt.plot(np.arange(1, len(self.err['train']) + 1), self.err['train'], label='Training Error')\n",
    "        if self.err['val']:\n",
    "            plt.plot(np.arange(1, len(self.err['val']) + 1), self.err['val'], label='Validation Error')\n",
    "        plt.legend(fontsize=15)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(array([5517, 1651, 4365, ..., 7581, 1720, 7367]), slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3628\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3629\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3630\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(array([5517, 1651, 4365, ..., 7581, 1720, 7367]), slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\3224057247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mboosting_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboosting_tree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2444\\3243495877.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, Y_train)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miter_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mX_train_subset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0my_predict_subset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# 用损失函数的负梯度作为回归树的残差近似值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3634\u001b[0m                 \u001b[1;31m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3635\u001b[0m                 \u001b[1;31m#  the TypeError.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3636\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3637\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Annaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5649\u001b[0m             \u001b[1;31m# if key is not a scalar, directly raise an error (the code below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5650\u001b[0m             \u001b[1;31m# would convert to numpy arrays and raise later any way) - GH29926\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5653\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (array([5517, 1651, 4365, ..., 7581, 1720, 7367]), slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "boosting_tree = XGBoost(max_depth=6)\n",
    "boosting_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = boosting_tree.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 28 2022, 08:03:21) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bda35a1e879a05a447a165f858b45568b1b1e2abd2947b4d01b6ed4acf0b7308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
