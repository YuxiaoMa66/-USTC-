{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = pd.read_csv(\"./Dataset/train_feature.csv\")\n",
    "data_label = pd.read_csv(\"./Dataset/train_label.csv\")\n",
    "test_feature = pd.read_csv(\"./Dataset/test_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.116155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  10000.000000\n",
       "mean       1.488900\n",
       "std        1.116155\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        2.000000\n",
       "max        3.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始数据合并与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_feature,data_label],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 0, 49.06611570247934)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = data.columns\n",
    "cntnull = []\n",
    "for i in range(len(names)):\n",
    "    cntnull.append(data[names[i]].isnull().sum())\n",
    "max(cntnull), min(cntnull), sum(cntnull)/len(cntnull)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.804220</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.157242</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>1.122944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.732584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-15.118262</td>\n",
       "      <td>0.590192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.276093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583108</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.852767</td>\n",
       "      <td>4.685032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.601408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.691250</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.907026</td>\n",
       "      <td>0.927391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.129846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.867626</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.992557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173169</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.165119</td>\n",
       "      <td>7.096296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.474665</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.256328</td>\n",
       "      <td>5838.357604</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758844</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.029199</td>\n",
       "      <td>11.567181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.226799</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>50.0</td>\n",
       "      <td>6.267244</td>\n",
       "      <td>0.446096</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.586553</td>\n",
       "      <td>...</td>\n",
       "      <td>2.267124</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.132499</td>\n",
       "      <td>1.310972</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>3.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.279090</td>\n",
       "      <td>0.143929</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435415</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>1.328274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.707751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.814346</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.580825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334893</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.237845</td>\n",
       "      <td>1.219853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.555282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.271178</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.266668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366215</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>1.428329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.565160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36.0</td>\n",
       "      <td>9.613106</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.449848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.728888</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.049360</td>\n",
       "      <td>0.286351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.174472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5486 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1    feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          48.0   9.804220     0.064283        6.0        5.0      211.0   \n",
       "1          45.0 -15.118262     0.590192       10.0        2.0      141.0   \n",
       "2          56.0   1.691250     0.173249        8.0        1.0      251.0   \n",
       "3          50.0   5.867626     0.004743        8.0        3.0      186.0   \n",
       "6          56.0   4.256328  5838.357604        9.0        5.0      222.0   \n",
       "...         ...        ...          ...        ...        ...        ...   \n",
       "9994       50.0   6.267244     0.446096       11.0        2.0      186.0   \n",
       "9995       67.0   1.279090     0.143929       10.0        3.0      210.0   \n",
       "9996       56.0   4.814346     0.697155        6.0        6.0      267.0   \n",
       "9997       57.0  -0.271178     0.579603        8.0        5.0      168.0   \n",
       "9999       36.0   9.613106     0.680197        8.0        4.0      162.0   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0          45.0        8.0        3.0   2.711200  ...     1.157242   \n",
       "1          48.0        7.0        1.0   3.276093  ...     0.583108   \n",
       "2          47.0        6.0        1.0   1.082628  ...     0.741096   \n",
       "3          39.0        8.0        1.0   2.992557  ...     1.173169   \n",
       "6          61.0        6.0        2.0   0.408384  ...     0.758844   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9994       47.0        9.0        8.0   0.586553  ...     2.267124   \n",
       "9995       51.0        8.0        1.0   0.670449  ...     1.435415   \n",
       "9996       44.0        9.0        2.0   0.580825  ...     0.334893   \n",
       "9997       57.0        8.0        5.0  14.266668  ...     1.366215   \n",
       "9999       52.0        7.0        1.0   3.449848  ...     1.728888   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0            44.0     0.027881     1.122944          0.0         47.0   \n",
       "1            62.0     0.852767     4.685032          1.0         38.0   \n",
       "2            62.0     0.907026     0.927391          2.0         53.0   \n",
       "3            60.0     0.165119     7.096296          1.0         56.0   \n",
       "6            44.0     0.029199    11.567181          0.0         63.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9994         44.0     0.132499     1.310972          2.0         63.0   \n",
       "9995         50.0     0.607483     1.328274          4.0         49.0   \n",
       "9996         63.0     0.237845     1.219853          1.0         55.0   \n",
       "9997         45.0     0.491556     1.428329          2.0         59.0   \n",
       "9999         50.0     0.049360     0.286351          3.0         50.0   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        1.732584          2.0         52.0      0  \n",
       "1        0.601408          2.0         44.0      0  \n",
       "2        2.129846          1.0         46.0      0  \n",
       "3        0.474665          2.0         38.0      2  \n",
       "6        0.226799          2.0         43.0      0  \n",
       "...           ...          ...          ...    ...  \n",
       "9994     0.039158          3.0         44.0      1  \n",
       "9995     0.707751          1.0         52.0      1  \n",
       "9996     0.555282          4.0         52.0      3  \n",
       "9997     1.565160          2.0         41.0      0  \n",
       "9999     1.174472          1.0         54.0      0  \n",
       "\n",
       "[5486 rows x 121 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试一下全部删去空值的时候剩下什么\n",
    "data0 = data.copy(deep=True).dropna()\n",
    "data0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清理了太多数据，考虑还是填充，用前一行的值填补空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='pad', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000.00000\n",
       "mean       1526.86640\n",
       "std       22861.25555\n",
       "min          24.00000\n",
       "25%          45.00000\n",
       "50%          50.00000\n",
       "75%          54.00000\n",
       "max      632196.00000\n",
       "Name: feature_116, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_116'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(data['feature_116'].dropna())\t\t\t\t#数据集\n",
    "plt.boxplot(x)    \t\t\t\t#垂直显示箱线图\n",
    "plt.show()\t\t\t\t\t\t#显示该图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(count     10000\n",
       " unique        2\n",
       " top       False\n",
       " freq       9947\n",
       " Name: feature_116, dtype: object,\n",
       " count     10000\n",
       " unique        2\n",
       " top       False\n",
       " freq       9947\n",
       " Name: feature_116, dtype: object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_116']>10000).describe(), (data['feature_116']>100).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "116属性里面有53个异常数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10000\n",
       "unique        2\n",
       "top       False\n",
       "freq       9944\n",
       "Name: feature_119, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_119']>100).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，119里面有56个，那合理怀疑前面的也有这种异常大的数据存在"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>9.804220</td>\n",
       "      <td>0.064283</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.711200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.157242</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.027881</td>\n",
       "      <td>1.122944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.732584</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>-15.118262</td>\n",
       "      <td>0.590192</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.276093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583108</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.852767</td>\n",
       "      <td>4.685032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.601408</td>\n",
       "      <td>2.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.691250</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.082628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741096</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.907026</td>\n",
       "      <td>0.927391</td>\n",
       "      <td>2.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.129846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.867626</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.992557</td>\n",
       "      <td>...</td>\n",
       "      <td>1.173169</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.165119</td>\n",
       "      <td>7.096296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.474665</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.0</td>\n",
       "      <td>-6.160454</td>\n",
       "      <td>0.709718</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.189316</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068687</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.600518</td>\n",
       "      <td>4.988225</td>\n",
       "      <td>7.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.187483</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.279090</td>\n",
       "      <td>0.143929</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.670449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435415</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.607483</td>\n",
       "      <td>1.328274</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.707751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56.0</td>\n",
       "      <td>4.814346</td>\n",
       "      <td>0.697155</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.580825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334893</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.237845</td>\n",
       "      <td>1.219853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.555282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>57.0</td>\n",
       "      <td>-0.271178</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.266668</td>\n",
       "      <td>...</td>\n",
       "      <td>1.366215</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.491556</td>\n",
       "      <td>1.428329</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.565160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.022212</td>\n",
       "      <td>0.839743</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.695831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561938</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.508272</td>\n",
       "      <td>3.113039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60192.0</td>\n",
       "      <td>0.727227</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>36.0</td>\n",
       "      <td>9.613106</td>\n",
       "      <td>0.680197</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.449848</td>\n",
       "      <td>...</td>\n",
       "      <td>1.728888</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.049360</td>\n",
       "      <td>0.286351</td>\n",
       "      <td>3.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.174472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0          48.0   9.804220   0.064283        6.0        5.0      211.0   \n",
       "1          45.0 -15.118262   0.590192       10.0        2.0      141.0   \n",
       "2          56.0   1.691250   0.173249        8.0        1.0      251.0   \n",
       "3          50.0   5.867626   0.004743        8.0        3.0      186.0   \n",
       "4          49.0  -6.160454   0.709718        9.0        3.0      240.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9995       67.0   1.279090   0.143929       10.0        3.0      210.0   \n",
       "9996       56.0   4.814346   0.697155        6.0        6.0      267.0   \n",
       "9997       57.0  -0.271178   0.579603        8.0        5.0      168.0   \n",
       "9998       52.0  -1.022212   0.839743        8.0        1.0      242.0   \n",
       "9999       36.0   9.613106   0.680197        8.0        4.0      162.0   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0          45.0        8.0        3.0   2.711200  ...     1.157242   \n",
       "1          48.0        7.0        1.0   3.276093  ...     0.583108   \n",
       "2          47.0        6.0        1.0   1.082628  ...     0.741096   \n",
       "3          39.0        8.0        1.0   2.992557  ...     1.173169   \n",
       "4          57.0        6.0        1.0   3.189316  ...     1.068687   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9995       51.0        8.0        1.0   0.670449  ...     1.435415   \n",
       "9996       44.0        9.0        2.0   0.580825  ...     0.334893   \n",
       "9997       57.0        8.0        5.0  14.266668  ...     1.366215   \n",
       "9998       37.0       10.0        3.0   0.695831  ...     0.561938   \n",
       "9999       52.0        7.0        1.0   3.449848  ...     1.728888   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0            44.0     0.027881     1.122944          0.0         47.0   \n",
       "1            62.0     0.852767     4.685032          1.0         38.0   \n",
       "2            62.0     0.907026     0.927391          2.0         53.0   \n",
       "3            60.0     0.165119     7.096296          1.0         56.0   \n",
       "4            54.0     0.600518     4.988225          7.0         52.0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995         50.0     0.607483     1.328274          4.0         49.0   \n",
       "9996         63.0     0.237845     1.219853          1.0         55.0   \n",
       "9997         45.0     0.491556     1.428329          2.0         59.0   \n",
       "9998         55.0     0.508272     3.113039          1.0      60192.0   \n",
       "9999         50.0     0.049360     0.286351          3.0         50.0   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        1.732584          2.0         52.0      0  \n",
       "1        0.601408          2.0         44.0      0  \n",
       "2        2.129846          1.0         46.0      0  \n",
       "3        0.474665          2.0         38.0      2  \n",
       "4        1.187483          2.0         38.0      2  \n",
       "...           ...          ...          ...    ...  \n",
       "9995     0.707751          1.0         52.0      1  \n",
       "9996     0.555282          4.0         52.0      3  \n",
       "9997     1.565160          2.0         41.0      0  \n",
       "9998     0.727227          3.0         65.0      0  \n",
       "9999     1.174472          1.0         54.0      0  \n",
       "\n",
       "[10000 rows x 121 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.000000e+04\n",
       "mean     5.137623e+03\n",
       "std      8.306486e+04\n",
       "min      0.000000e+00\n",
       "25%      1.620000e+02\n",
       "50%      1.940000e+02\n",
       "75%      2.220000e+02\n",
       "max      2.072000e+06\n",
       "Name: feature_5, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['feature_5']).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注：** 之前处理方式在最后的建模预测中的表现并不好模型都只有不到30%的准确率，因此重新预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 0, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "datanames = names.drop('label')\n",
    "list100 = []\n",
    "for obj in datanames:\n",
    "    if np.median(data[obj]) > 100:\n",
    "        list100.append(0)\n",
    "    elif np.median(data[obj]) <= 100 and np.median(data[obj]) > 10:\n",
    "        list100.append(1)\n",
    "    else:\n",
    "        list100.append(2)\n",
    "print(list100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['feature_0'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找整型列，由于数据将整型保存成float64而不是int64/32，故只能重新判断\n",
    "def judgeint(data, colnames):\n",
    "    # 如果超过95%的数据都是整数就认为是整数，并将数据处理成整数\n",
    "    jud = []\n",
    "    for obj in colnames:\n",
    "        cnt = 0\n",
    "        for i in data[obj]:\n",
    "            if i.is_integer():\n",
    "                cnt += 1\n",
    "        if cnt/len(data[obj]) > 0.95:\n",
    "            data[obj] = data[obj].astype(np.int64)\n",
    "            jud.append(1)\n",
    "        else:\n",
    "            jud.append(0)\n",
    "    return jud\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "list_isint = judgeint(data, datanames)\n",
    "print(list_isint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 对float的列进行预处理\n",
    "# data_float_names = data.select_dtypes(include=float).columns\n",
    "# data1 = data.copy(deep=True)\n",
    "# def sigmoid(X):\n",
    "#     if X >= 0:\n",
    "#         return 1.0 / (1 + np.exp(-X))\n",
    "#     else:   # 防止上溢\n",
    "#         return np.exp(X)/(np.exp(X)+1)\n",
    "# # 考虑到平均数由异常值的影响很大，掐头去尾取平均数和取中位数区别不大，取中位数来减\n",
    "# for obj in data_float_names:\n",
    "#     med = np.median(data1[obj])\n",
    "#     data1[obj] = data1[obj]-med\n",
    "#     for i in range(len(data1[obj])):\n",
    "#         data1[obj][i] = sigmoid(data1[obj][i])\n",
    "    \n",
    "# data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20123\\AppData\\Local\\Temp/ipykernel_3368/4067329763.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[obj][data1[obj]>np.percentile(data1[obj], 95)] = np.percentile(data1[obj], 95)\n",
      "C:\\Users\\20123\\AppData\\Local\\Temp/ipykernel_3368/4067329763.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n",
      "C:\\Users\\20123\\AppData\\Local\\Temp/ipykernel_3368/4067329763.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n",
      "C:\\Users\\20123\\AppData\\Local\\Temp/ipykernel_3368/4067329763.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n"
     ]
    }
   ],
   "source": [
    "data1 = data.copy(deep=True)\n",
    "# # data_int_names = data.select_dtypes(include=int).columns.drop('label')\n",
    "# # data_float_names = data.select_dtypes(include=float).columns\n",
    "\n",
    "# 如果出现异常数据就用5%和95%的分位数取取边界值\n",
    "for obj in datanames:\n",
    "    # 肉眼观察最大值都大于0\n",
    "    if (max(data1[obj])>=0 and np.percentile(data1[obj], 95)>=0) and max(data1[obj]) > np.percentile(data1[obj], 95)*100:\n",
    "        data1[obj][data1[obj]>np.percentile(data1[obj], 95)] = np.percentile(data1[obj], 95)\n",
    "    # 最小值分类处理\n",
    "    if (min(data1[obj])>=0 and np.percentile(data1[obj], 5)>=0) and np.percentile(data1[obj], 5)-min(data1[obj]) > np.percentile(data1[obj], 95)/100:\n",
    "        data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n",
    "    if (min(data1[obj])<0 and np.percentile(data1[obj], 5)>=0) and np.percentile(data1[obj], 5)+min(data1[obj]) < min(data1[obj])/100:\n",
    "        data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n",
    "    if (min(data1[obj])<0 and np.percentile(data1[obj], 5)<0) and np.abs(np.percentile(data1[obj], 5)-min(data1[obj])) > np.abs(min(data1[obj])/100):\n",
    "        data1[obj][data1[obj]<np.percentile(data1[obj], 5)] = np.percentile(data1[obj], 5)\n",
    "    # # 归一化\n",
    "    # data1[obj] = (data1[obj]-np.min(data1[obj]))/(np.max(data1[obj])-np.min(data1[obj]))   \n",
    "\n",
    "## 小波变换去噪\n",
    "import pywt\n",
    "\n",
    "w = pywt.Wavelet('db8')  # 选用Daubechies8小波\n",
    "maxlev = pywt.dwt_max_level(len(data1), w.dec_len)\n",
    "threshold = 0.2  # Threshold for filtering\n",
    "for obj in datanames:\n",
    "    lis = list(data1[obj])\n",
    "    coeffs = pywt.wavedec(lis, 'db8', level=maxlev)  # 将信号进行小波分解\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))  # 将噪声滤波\n",
    "    datarec = pywt.waverec(coeffs, 'db8')  # 将信号进行小波重构\n",
    "    data1[obj] = datarec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_111</th>\n",
       "      <th>feature_112</th>\n",
       "      <th>feature_113</th>\n",
       "      <th>feature_114</th>\n",
       "      <th>feature_115</th>\n",
       "      <th>feature_116</th>\n",
       "      <th>feature_117</th>\n",
       "      <th>feature_118</th>\n",
       "      <th>feature_119</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.845042</td>\n",
       "      <td>6.573727</td>\n",
       "      <td>0.161104</td>\n",
       "      <td>6.403413</td>\n",
       "      <td>3.933724</td>\n",
       "      <td>217.497487</td>\n",
       "      <td>47.730239</td>\n",
       "      <td>7.842683</td>\n",
       "      <td>2.529695</td>\n",
       "      <td>2.705949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.939187</td>\n",
       "      <td>44.707326</td>\n",
       "      <td>0.140899</td>\n",
       "      <td>2.488341</td>\n",
       "      <td>0.351185</td>\n",
       "      <td>48.485423</td>\n",
       "      <td>1.303365</td>\n",
       "      <td>1.782620</td>\n",
       "      <td>50.420674</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47.798520</td>\n",
       "      <td>-11.180121</td>\n",
       "      <td>0.534687</td>\n",
       "      <td>9.113712</td>\n",
       "      <td>3.243493</td>\n",
       "      <td>157.527464</td>\n",
       "      <td>48.126192</td>\n",
       "      <td>7.436167</td>\n",
       "      <td>2.299441</td>\n",
       "      <td>2.592263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.889274</td>\n",
       "      <td>55.255558</td>\n",
       "      <td>0.661187</td>\n",
       "      <td>4.120156</td>\n",
       "      <td>0.778675</td>\n",
       "      <td>43.547844</td>\n",
       "      <td>0.538352</td>\n",
       "      <td>1.812900</td>\n",
       "      <td>47.504671</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.949880</td>\n",
       "      <td>3.364694</td>\n",
       "      <td>0.270831</td>\n",
       "      <td>7.423391</td>\n",
       "      <td>2.455442</td>\n",
       "      <td>227.198544</td>\n",
       "      <td>48.185355</td>\n",
       "      <td>6.651749</td>\n",
       "      <td>1.695024</td>\n",
       "      <td>2.800268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821068</td>\n",
       "      <td>55.267186</td>\n",
       "      <td>0.728334</td>\n",
       "      <td>3.993271</td>\n",
       "      <td>1.844840</td>\n",
       "      <td>53.933791</td>\n",
       "      <td>1.354138</td>\n",
       "      <td>1.703431</td>\n",
       "      <td>45.106766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.773459</td>\n",
       "      <td>5.525551</td>\n",
       "      <td>0.307101</td>\n",
       "      <td>7.977140</td>\n",
       "      <td>3.105506</td>\n",
       "      <td>192.130188</td>\n",
       "      <td>43.148031</td>\n",
       "      <td>7.766001</td>\n",
       "      <td>1.378197</td>\n",
       "      <td>2.994769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806432</td>\n",
       "      <td>57.779541</td>\n",
       "      <td>0.169429</td>\n",
       "      <td>5.181636</td>\n",
       "      <td>1.544736</td>\n",
       "      <td>53.745669</td>\n",
       "      <td>0.764895</td>\n",
       "      <td>1.584312</td>\n",
       "      <td>42.191909</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.513779</td>\n",
       "      <td>-2.542518</td>\n",
       "      <td>0.689279</td>\n",
       "      <td>7.986304</td>\n",
       "      <td>3.372349</td>\n",
       "      <td>215.139682</td>\n",
       "      <td>54.337638</td>\n",
       "      <td>6.578284</td>\n",
       "      <td>1.623128</td>\n",
       "      <td>3.095930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>51.130683</td>\n",
       "      <td>0.582694</td>\n",
       "      <td>4.107318</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>51.891107</td>\n",
       "      <td>1.155409</td>\n",
       "      <td>1.867461</td>\n",
       "      <td>43.692459</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>57.793970</td>\n",
       "      <td>3.989251</td>\n",
       "      <td>0.447398</td>\n",
       "      <td>8.773465</td>\n",
       "      <td>3.250243</td>\n",
       "      <td>197.562121</td>\n",
       "      <td>50.621306</td>\n",
       "      <td>8.248438</td>\n",
       "      <td>1.245856</td>\n",
       "      <td>2.285148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.512824</td>\n",
       "      <td>50.281449</td>\n",
       "      <td>0.443650</td>\n",
       "      <td>2.328350</td>\n",
       "      <td>3.146931</td>\n",
       "      <td>49.799844</td>\n",
       "      <td>0.852492</td>\n",
       "      <td>1.372668</td>\n",
       "      <td>51.648562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>54.798583</td>\n",
       "      <td>3.404005</td>\n",
       "      <td>0.623274</td>\n",
       "      <td>6.743573</td>\n",
       "      <td>4.745438</td>\n",
       "      <td>222.271921</td>\n",
       "      <td>46.768947</td>\n",
       "      <td>8.004469</td>\n",
       "      <td>2.113303</td>\n",
       "      <td>1.314659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740331</td>\n",
       "      <td>58.925174</td>\n",
       "      <td>0.277291</td>\n",
       "      <td>2.067634</td>\n",
       "      <td>1.655270</td>\n",
       "      <td>55.141202</td>\n",
       "      <td>1.042938</td>\n",
       "      <td>2.681528</td>\n",
       "      <td>54.032335</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>51.789150</td>\n",
       "      <td>2.078580</td>\n",
       "      <td>0.617104</td>\n",
       "      <td>7.702516</td>\n",
       "      <td>4.282364</td>\n",
       "      <td>160.557883</td>\n",
       "      <td>53.449733</td>\n",
       "      <td>8.016304</td>\n",
       "      <td>3.511304</td>\n",
       "      <td>10.623468</td>\n",
       "      <td>...</td>\n",
       "      <td>1.415569</td>\n",
       "      <td>45.603998</td>\n",
       "      <td>0.337076</td>\n",
       "      <td>1.915265</td>\n",
       "      <td>1.957277</td>\n",
       "      <td>55.250141</td>\n",
       "      <td>1.132279</td>\n",
       "      <td>1.998136</td>\n",
       "      <td>45.332954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>48.615279</td>\n",
       "      <td>1.267875</td>\n",
       "      <td>0.656263</td>\n",
       "      <td>7.871225</td>\n",
       "      <td>1.971666</td>\n",
       "      <td>222.461532</td>\n",
       "      <td>42.912996</td>\n",
       "      <td>8.909926</td>\n",
       "      <td>1.961712</td>\n",
       "      <td>2.135458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707545</td>\n",
       "      <td>53.625828</td>\n",
       "      <td>0.400513</td>\n",
       "      <td>1.851748</td>\n",
       "      <td>1.926886</td>\n",
       "      <td>59.493291</td>\n",
       "      <td>1.024407</td>\n",
       "      <td>2.461506</td>\n",
       "      <td>58.071487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>44.151322</td>\n",
       "      <td>3.098541</td>\n",
       "      <td>0.658582</td>\n",
       "      <td>8.698905</td>\n",
       "      <td>3.361413</td>\n",
       "      <td>190.199937</td>\n",
       "      <td>48.655144</td>\n",
       "      <td>7.827455</td>\n",
       "      <td>1.943844</td>\n",
       "      <td>3.915440</td>\n",
       "      <td>...</td>\n",
       "      <td>1.188586</td>\n",
       "      <td>48.987491</td>\n",
       "      <td>0.291069</td>\n",
       "      <td>1.740407</td>\n",
       "      <td>2.341908</td>\n",
       "      <td>53.643301</td>\n",
       "      <td>0.990129</td>\n",
       "      <td>1.957297</td>\n",
       "      <td>54.937525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4   feature_5  \\\n",
       "0     47.845042   6.573727   0.161104   6.403413   3.933724  217.497487   \n",
       "1     47.798520 -11.180121   0.534687   9.113712   3.243493  157.527464   \n",
       "2     51.949880   3.364694   0.270831   7.423391   2.455442  227.198544   \n",
       "3     51.773459   5.525551   0.307101   7.977140   3.105506  192.130188   \n",
       "4     48.513779  -2.542518   0.689279   7.986304   3.372349  215.139682   \n",
       "...         ...        ...        ...        ...        ...         ...   \n",
       "9995  57.793970   3.989251   0.447398   8.773465   3.250243  197.562121   \n",
       "9996  54.798583   3.404005   0.623274   6.743573   4.745438  222.271921   \n",
       "9997  51.789150   2.078580   0.617104   7.702516   4.282364  160.557883   \n",
       "9998  48.615279   1.267875   0.656263   7.871225   1.971666  222.461532   \n",
       "9999  44.151322   3.098541   0.658582   8.698905   3.361413  190.199937   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_111  \\\n",
       "0     47.730239   7.842683   2.529695   2.705949  ...     0.939187   \n",
       "1     48.126192   7.436167   2.299441   2.592263  ...     0.889274   \n",
       "2     48.185355   6.651749   1.695024   2.800268  ...     0.821068   \n",
       "3     43.148031   7.766001   1.378197   2.994769  ...     0.806432   \n",
       "4     54.337638   6.578284   1.623128   3.095930  ...     0.805110   \n",
       "...         ...        ...        ...        ...  ...          ...   \n",
       "9995  50.621306   8.248438   1.245856   2.285148  ...     1.512824   \n",
       "9996  46.768947   8.004469   2.113303   1.314659  ...     0.740331   \n",
       "9997  53.449733   8.016304   3.511304  10.623468  ...     1.415569   \n",
       "9998  42.912996   8.909926   1.961712   2.135458  ...     0.707545   \n",
       "9999  48.655144   7.827455   1.943844   3.915440  ...     1.188586   \n",
       "\n",
       "      feature_112  feature_113  feature_114  feature_115  feature_116  \\\n",
       "0       44.707326     0.140899     2.488341     0.351185    48.485423   \n",
       "1       55.255558     0.661187     4.120156     0.778675    43.547844   \n",
       "2       55.267186     0.728334     3.993271     1.844840    53.933791   \n",
       "3       57.779541     0.169429     5.181636     1.544736    53.745669   \n",
       "4       51.130683     0.582694     4.107318     3.873311    51.891107   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "9995    50.281449     0.443650     2.328350     3.146931    49.799844   \n",
       "9996    58.925174     0.277291     2.067634     1.655270    55.141202   \n",
       "9997    45.603998     0.337076     1.915265     1.957277    55.250141   \n",
       "9998    53.625828     0.400513     1.851748     1.926886    59.493291   \n",
       "9999    48.987491     0.291069     1.740407     2.341908    53.643301   \n",
       "\n",
       "      feature_117  feature_118  feature_119  label  \n",
       "0        1.303365     1.782620    50.420674      0  \n",
       "1        0.538352     1.812900    47.504671      0  \n",
       "2        1.354138     1.703431    45.106766      0  \n",
       "3        0.764895     1.584312    42.191909      2  \n",
       "4        1.155409     1.867461    43.692459      2  \n",
       "...           ...          ...          ...    ...  \n",
       "9995     0.852492     1.372668    51.648562      1  \n",
       "9996     1.042938     2.681528    54.032335      3  \n",
       "9997     1.132279     1.998136    45.332954      0  \n",
       "9998     1.024407     2.461506    58.071487      0  \n",
       "9999     0.990129     1.957297    54.937525      0  \n",
       "\n",
       "[10000 rows x 121 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000) (120,) (120, 120)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAteElEQVR4nO3deZxcVZn/8c9T1elOCCRkYUvIBgQ0CAg0IJuAawAlIiqyqAgSo2TAQQdwUFQYAXH/DWCICIwiRHDNOCAiI7jiJMgiYVgCsiQYAmECAZJ0uuv5/XFOdd9ac6u7qnr7vl+venVV3XvuObe66j733HPuOebuiIiIJGX6uwAiIjLwKDiIiEgJBQcRESmh4CAiIiUUHEREpISCg4iIlGjp7wLUw8SJE3369On9XQwRkUHlnnvuecHdtym3bEgEh+nTp7N06dL+LoaIyKBiZk9VWqbLSiIiUkLBQURESig4iIhICQUHEREpoeAgIiIlFBxERKTEsA4OGzZ1seqlDWzqyvV3UUREBpRhHRxuf+g53nTJHTz5wqv9XRQRkQFlWAeHlowB0KUJj0RECgzr4JCJwaGzS8FBRCSp18HBzF5nZu8xs0n1LFAz5WsOOdUcREQKpAoOZnaVmS1IvD4e+BvwU+BhMzuoQeVrqO6aQ07BQUQkKW3NYTbwu8Tri4AbgUnAbfH1oNNdc1BwEBEpkDY4bAs8A2BmM4FdgMvcfRWwENi7McVrrKyp5iAiUk7a4PAisF18/jZglbs/GF8bkK13wZohq5qDiEhZaedzuBW40My2A84BbkosewPwZJ3L1RRZtTmIiJSVtubwaeBuYB6h7eELiWXHAr+qc7maIqv7HEREykpVc3D3l4BTKyw7tK4laqLu4KD7HERECtQ0TaiZzQL2BaYA17j7KjPbBXjO3dc1ooCNpJqDiEh5qYKDmW0JXAO8D9gU0/0KWAVcDDwNfKZBZWyY7uCgNgcRkQJp2xy+ARwEvBXYitBDKe8Wwn0Qg06LgoOISFlpLyu9FzjL3X9rZsXdVp8CptW3WM2RMQUHEZFy0tYcRgFrKizbCuiqT3GaqyUTdl/BQUSkUNrgsAT4cIVl7wP+VJ/iNFeMDQoOIiJF0l5W+hzwGzP7DXAz4MBRZvbPhODw5gaVr6G6aw7qrSQiUiBVzcHd/0BojG4DLic0SH8J2Al4m7svaVgJGyhfc9Ad0iIihVLf5+DufwQONbNRwDhgrbu/1rCSNUG+5qCxlURECtV0ExyAu68H1jegLE2nUVlFRMpLexPcTZtbx90/0PfiNFc2q1FZRUTKSdtbaZsyj92AY4CDgYlpMzSz2Wb2iJktN7Pzyiw/3MxeMrP74uOCtNuulWoOIiLlpR1474hy75vZFOBnwDfTbCfeQHcF8HZgBbDEzBa7+0NFq/7e3d+VZpt9kdUc0iIiZaWtOZTl7s8AlwCXpUyyP7Dc3Z9w9w5gETCnL2Xoi+75HDQqq4hIgT4Fh6gL2DHlupOJ041GK+J7xQ40s/vN7FYz273chsxsrpktNbOlzz//fG0ljmJs0H0OIiJF0jZIzyrzdivweuAiwh3UqTZV5r3iI/NfgWnu/oqZHQX8HJhZksh9IWH+atrb23t1dDczshmjK5frTXIRkSErbVfWByk9iEM42C8BPpZyOysIc0Hk7Qg8m1zB3V9OPL/FzK40s4nu/kLKPGoSgkMjtiwiMnilDQ7lGqQ3ACvcfWUN+S0BZprZDGAl8EHgxOQKZrY9YfIgN7P9CZe+Kg3612dZU81BRKRY2t5Kd9UjM3fvNLP5wG1AljCb3DIzmxeXLyCM1fQJM+sk3Gz3QffGNQq0qOYgIlKiYnAwsy1q2VDaoTTc/RbCBEHJ9xYknl9OGL+pKTJqcxARKVGt5vAK5dsZKimeBGhQaMmYeiuJiBSpFhxOpbbgMCiFmsOQ300RkZpUDA7ufl0Ty9FvWhQcRERK1OMmuEEtY6axlUREiqQestvMjgdOB3YFRhYvd/dt61iupmnJmkZlFREpkqrmYGYnAv8BLCfcuLYY+GVM/zJN7F1Ub1nVHERESqS9rPQvhGEyzoivr3T3U4EZwAvAoJ0RLpMxjcoqIlIkbXCYCfzR3bsIA+2NAXD3dcBXgPmNKV7jtWRMo7KKiBRJGxxeAtri85WEAffyDJhQz0I1U8ZUcxARKZa2QXopsCdh2IvFwAVxeIsO4ALgL40pXuO1ZNXmICJSLG1wuASYFp9fEJ9fSbgregkwt/5Fa46M6T4HEZFiaQfeuxu4Oz5fC8wxszagLTnE9mCkm+BEREql7cr6UTMbm3zP3TcO9sAAGj5DRKSctA3SC4DnzGyxmZ1oZqMbWahmUs1BRKRU2uCwHfBJwtSg1wGrzezHZnacmZXcLT2YZDUqq4hIiVTBwd3Xuvs17j4b2AE4GxgH/IgQKK5vYBkbKquag4hIiZoH3nP3Ne5+lbu/FZgDrANOqHvJmiSr3koiIiVSD7yXZ2Z7AMfHx07A48DFdS5X06jmICJSKlVwMLPXAx8gBITdgGeAm4BF7v7XxhWv8RQcRERKpa05LAP+AdwMnObuf25ckZpLwUFEpFTa4PAW4C73odetR72VRERKpb1D+s4Gl6PfZDUqq4hIiWE/TWhWo7KKiJQY9sFBo7KKiJQa9sEhY5pDWkSk2GaDg5m1mdlJZjazHhma2Wwze8TMlpvZeVXW28/MuszsffXIt5IWNUiLiJTYbHBw943A1cCkvmZmZlngCuBIYBZwgpnNqrDeVwiTCzVUJmN0qUFaRKRA2stKfwN2rUN++wPL3f0Jd+8AFhGG4Cj2T8BPgNV1yLMq1RxEREqlDQ7/DJxjZu8ys5qH3EiYTLi7Om9FfK+bmU0GjiUME95wmYwapEVEiqU90P8c2AL4BeBm9n9AwRHV3bdNsR0r817xkflbwLnu3mVWbvW4IbO5xOlJp06dmiLr8loyapAWESmWNjhcQelBvDdWAFMSr3cEni1apx1YFAPDROAoM+t0958nV3L3hcBCgPb29l6XLWuqOYiIFEt7h/QX65TfEmCmmc0AVgIfBE4symtG/rmZXQf8sjgw1FM2E66s5XJOJlO5piIiMpz0pf2gZu7eaWbzCb2QssA17r7MzObF5U1pZ0jKxlaXzpzTquAgIgLUEBzM7EDgNEKvpZKpQd19/zTbcfdbgFuK3isbFNz9lLTl663umoN6LImIdEvVW8nM3g78jtBGcAjwPPAKsBcwAXiwUQVstGTNQUREgrRdWS8Evg0cHV9/3t3fQqhFbALurH/RmiNfc9CcDiIiPdIGh1nArUCO0GtpNIC7PwV8ETi/EYVrhmxsZlBwEBHpkTY4bAAycbKffwA7J5a9TLjcNChls6o5iIgUS9sgfT9h7ujbgTuAz5rZSqCDcMnpb40pXuNl4412Cg4iIj3S1hy+Rc9NcP8KvErojvpbYFvgjLqXrElaYvdVja8kItIj7U1wtySerzSzfYFdgFHAw3EQvUEpf+ObRmYVEenRq5vgYtvDY3UuS79QzUFEpFTF4GBmn6xhO+7u36lDeZquu+aQy/VzSUREBo5qNYfLa9iOA4MyOHTXHBQbRES6VQwO7j4s5pfOxN5Knao5iIh0GxYBoJp8zUGxQUSkR6oGaTM7anPrJHs0DSbZjGoOIiLF0vZW+iWhXaF4TOtkF59sXUrUZPngoFFZRUR6pA0OM8q8Nx54B3AK8NF6FajZumsOus9BRKRb2pvgnirz9lPAvWbWRbhr+ph6FqxZsrrPQUSkRD0apO8F3lKH7fSL7uCgsZVERLr1KTiYWSvhstI/6lKafqDgICJSKm1vpSUUNj4DtALTga0YzG0OGpVVRKRE2gbpZZQGhw3AzcDP3X1ZXUvVRKo5iIiUStsgfUqDy9FvFBxERErpDmn1VhIRKZG2zeG3lF5WyssRpgq9D7jW3Z+pT9GaI6Oag4hIibQ1hxcIk/scQpjg55X49xBgV2A0cCawzMz2a0A5G6ZFwUFEpETa4PBL4Hlgursf6O7HuPuBhDunXyA0TO8EPARc0pCSNkjPqKwKDiIieWmDwwXAhe7+bPJNd18JXAic7+4vA98ADqhvERurJZsflVXBQUQkL21w2AFoq7BsJLBdfL6a0sH5CpjZbDN7xMyWm9l5ZZbPMbMHzOw+M1tqZoekLGOvZFVzEBEpkTY43AVcamb7Jt80s3bCZaQ741szgacrbcTMssAVwJHALOAEM5tVtNodwF7u/kbgVODqlGXsFY3KKiJSKm1wmEvokfQ/ZrYyntWvBP4CrAU+ntjeZVW2sz+w3N2fcPcOYBEwJ7mCu7/i3n2kHk3lXlJ1oVFZRURKpb0J7hngjWZ2NNAObA+sApYkJ/lx96s2s6nJQLKr6wrKtFGY2bGEGsm2wNFpythbqjmIiJRKO3wGAO7+X8B/9SG/cu0RJUdld/8Z8DMzezNwEfC2kg2ZzSXUaJg6dWqvC9QzE5yCg4hIXk3BwczaCGf/I4uXuftDKTaxApiSeL0j8GyFdXH335nZzmY20d1fKFq2EFgI0N7e3usje0YD74mIlEh7h/QkwoH4yHKLCWf/aaYJXQLMNLMZwErgg8CJRXntAjzu7m5m+xBGf12Tppy9oZvgRERKpa05XA3sA5xNuNGtozeZuXunmc0HbiMEk2vcfZmZzYvLFwDHAR82s03AeuD4RAN13WngPRGRUmmDw8HA6e5+U18zjA3YtxS9tyDx/CvAV/qaT1pmRsYUHEREktJ2ZV1NOIsfkrIZ06isIiIJtQyfca6ZjWlkYfpLNmOqOYiIJKS9rPReYCrwVJwydG3Rcnf34+tZsGbKmoKDiEhS2uAwEXg8Ph8BbNOY4vQP1RxERAqlvUP6iEYXpD8pOIiIFBr204QCZDMZ3SEtIpJQseZgZp8Ebnb35+Pzqtz9yrqWrImyGc3nICKSVO2y0uXAUsIMcJdvZjsODNrg0KKag4hIgYrBwd0z5Z4PRZmMRmUVEUka0gf9tFRzEBEplCo4mNmhZjYn8Xqimd0QJ/35upmNaFwRGy9janMQEUlKW3O4DHhD4vW3gbcCdwOnAF+qb7GaK9Qccv1dDBGRASNtcNgNuAfAzLYAjgXOcvd5wDnAoL07GiCTMboUG0REuqUNDq3Ahvj8YEJDdn5GuEeBHepcrqZqyRhdqjmIiHRLGxweBmbH5ycBf3b3dfH1JODFehesmTIZo0tNDiIi3dKOrXQhcLOZnQaMBeYkls0G7q13wZpJNQcRkUJpx1ZabGavB/YG/ubujyYW/xl4oBGFaxaNyioiUihtzQF3fwJ4osz7C+taon6QzZh6K4mIJOgmODQqq4hIMQUHFBxERIopOKA5pEVEiik4ENsc1JdVRKRbTcHBgilmdpCZjW5UoZota6ZRWUVEElIHhzjhz0rgKeD3hCE1MLOfmtmnGlK6JslmTaOyiogkpB2V9V+AbwDfBd4CWGLxnQzysZWyZhqVVUQkIe19DmcAF7j7ZWaWLVr2CLBrfYvVXC0Z1RxERJLSXlbanjgqaxk5YGTaDM1stpk9YmbLzey8MstPMrMH4uNPZrZX2m33ViajmoOISFLa4LAcOKzCsjcDD6XZSKx1XAEcCcwCTjCzWUWr/R04zN33BC4CGn4HtmoOIiKF0l5W+hZwpZl1AD+O720bB+I7Gzg95Xb2B5bHoTgws0WEQfy6g4u7/ymx/t3Ajim33WuZjHoriYgkpR1472ozGwdcQM+sb7cArwFfdPcbUuY3GXgm8XoFcECV9U8Dbi23wMzmAnMBpk6dmjL78lp0h7SISIFaBt77qpktAA4EJhLmcPizu79UQ35W5r2yR2UzO4IQHA6pUJ6FxEtO7e3tfTqyZ0yXlUREklIFBzObCvxfnODn10XLRgA7uPvTKTa1ApiSeL0j8GyZ/PYErgaOdPc1acrYFy1qkBYRKZC2QfpJ4DEzK9covQ+hETmNJcBMM5thZq3AB4HFyRViIPop8KGieSMaJqsGaRGRArUMn/EYcLuZnd3bzNy9E5gP3Ab8L3CTuy8zs3lmNi+udgEwgdAAfp+ZLe1tfmll1SAtIlIgdZsD8GmgHfimme0HnObur9WaobvfQmjMTr63IPH8Y8DHat1uX6jmICJSqKaB99z9SuCtwOHA3Wa2cyMK1WzZjOGO2h1ERKKah+x29z8QahCvEdoQjq53oZota6ETleZ0EBEJejWfg7uvJNwZ/TPgc3UtUT/IZmNwUM1BRARI3+ZwBKEBuZu7dwCnmdkdwMx6F6yZumsOCg4iIkD6O6TvqrIs7d3RA1Y2o8tKIiJJFYNDnNznZnd/Pj6vxt39O/UtWvN0BwdNFSoiAlSvOVwOLAWej8+rcWDQBocW1RxERApUDA7unin3fCjKZNTmICKSNKQP+mm1KDiIiBSo1uZQPAlPVe6easKfgSij3koiIgWqtTk8SIXhtItYXK94bulBo0X3OYiIFKgWHI5oWin6Wb7moPGVRESCag3SFe9tGGpaMqHpRSOziogEtYzKCoCZZYCRxe/3ZoTWgSIbm+U7dZ+DiAiQsreSBeea2XJgE7CuzGPQyqrmICJSIG1X1jOB84DvERqgvwxcCDxKmCVubiMK1yzdNQe1OYiIAOmDw+nAF4DL4uufu/uXgN2BhxnsA+/FmoN6K4mIBGmDwwzgPnfvIlxW2hrA3XPAlcBHGlK6JtGorCIihdIGhzXAlvH508DeiWXjgFH1LFSzZXWHtIhIgbS9lf4I7EeY+/kG4ItmNh7oAM4A7mhM8ZpDwUFEpFDa4PBFYHJ8fjHhstIphBrD7cA/1blcTaX5HERECqWd7OcR4JH4fCNwVnwMCT01h1w/l0REZGDQqKwkG6T7uSAiIgNE6jukzewDwLGEy0vl7pDev47lairVHERECqUKDmZ2KXAOsARYTmiIHjJ6gkM/F0REZIBIW3M4FTjf3S/pa4ZmNhv4NmGI76vd/dKi5a8DrgX2iXl+ra95bk4+OHSq5iAiAqQPDpuAe/qamZllgSuAtwMrgCVmtrhooqAXCcN1vKev+aWVDw4aW0lEJEjbIP1t4GNmseW29/YHlrv7E+7eASwC5iRXcPfV7r6EEJCaIj9NqEZlFREJ0nZlvczMvgY8bGZ3AWtLV/FzU2xqMvBM4vUK4IA0ZWikjGoOIiIF0jZInwR8CsgRhtEobpB2IE1wKFfz6NUR2czmEkeDnTp1am820a275qA7pEVEgPRtDpcCPwLmuXtf5m5YAUxJvN4ReLY3G3L3hcBCgPb29j4d1fPThOYUHEREgPRtDmOAa/oYGCB0hZ1pZjPMrBX4ILC4j9vsM9UcREQKpa05/AQ4gj4OsOfunWY2H7iN0JX1GndfZmbz4vIFZrY9sJQQkHJm9ilglru/3Je8q8lo4D0RkQJpg8NtwKXxwP3flDZI4+63pNlQXO+WovcWJJ6vIlxuapoWBQcRkQJpg8ON8e+p8VHMCTWBQUmjsoqIFEobHGY0tBT9rDs46D4HEREgRXAws5HAd4GL3f3OhpeoH3SPyqqag4gIkKK3krtvIMwCN2gvG21OJmOYqc1BRCQvbVfWxTRxrKP+kDVTcBARiWrprfRVM9uB0NPoOYrubE7bW2mgymYUHERE8tIGh+vj3/fGR7FB3VsJFBxERJLUWynKZkx3SIuIRGlHZX2q0QXpb9mMaVRWEZGoljmkW4DjgEOA8YRJeX4P/NTdOxtTvOZpUc1BRKRb2iG7twV+DewJPElokD4QOAO438ze4e7PN6qQzZAx06isIiJR2q6s3wAmAAe4+07ufqC770SYqGdCXD6oqeYgItIjbXA4Cjg3Tt/ZLb7+LHB0vQvWbJmMag4iInlpg0MbUGkuh3VAa32K039UcxAR6ZE2ONwNnGtmo5NvxtfnxuWDWiZjGltJRCRK21vp08BvgWfM7NeEBultgXcS5oU+vCGla6KWjGlUVhGRKFXNwd3vA2YS5mzeBng7ITgsAGa6+/2NKmCzZEw1BxGRvNT3Obj7C8B5DSxLv2rJavgMEZG8tG0OQ17W1CAtIpJXseZgZv9dw3bc3d9ah/L0m0lbj+L2h57jqrse5/RDdyITZ4cTERmOql1WWpMi/Q7AQRQN3z0YXXrcnsADXHLrw/zp8TXMO2xn2qePY0RWlSsRGX4qBgd3f3+lZWY2ldCF9V3AC8A361+05ho7agRXnrQP1//lab78Xw9x16PPM2ZkC297/XbM2XsyB+88gRYFChEZJsxr6KFjZrsQ7og+GVgNfB24yt3XN6Z46bS3t/vSpUvrtr1XNnbyh8ee5/aHVvPrh1axbkMnE7ds4737TOb4/aaw8zZb1i0vEZH+Ymb3uHt72WVpgoOZ7Q6cD7wfeAa4DLjG3TvqWdDeqndwSNqwqYs7H1nNT/+6kjseXk1XzmmfNo4j99iBd+6+HTuO26Ih+YqINFqvg4OZ7UsICnOAR4FLgevdvasRBe2tRgaHpNXrNvDje1aw+L5neXhVGE1k2oQteMPksew+aQzTxo9m6vgt2H7sSMaPbiWrRm0RGcB6FRzM7FbgHcADwMXufnPjitg3zQoOSX9/4VVuf2gV9z69lgdWvMTKtYVX1jIG40e3stXIEWzZ1sKU8aNonzaefaaNY/wWrYwckWFUa5bRrS3qGSUi/aK3wSEXn74I5MqulODu26YszGzg24Q5p69290uLlltcfhTwGnCKu/+12jb7IzgUW7dhE8+8uJ6nX3yN1es28Py6jbzwSgevbOxk3YZNPPbcKyUBBMAMtmxrYcLoViZs2cbYUSNoyRgtWWPsqBFss9VIJoxupSVrZM3IZMLfbMYwy2/DyBgY4T2L24X4vhn58JPJ9KyXsfz6Yb1sxhjRkqE1m2HkiCxbtGZpbcmQtVCeLdtaMFMgExkqqgWHal1Zv9SAgmSBKwjDb6wAlpjZYnd/KLHakYShOmYS5ov4Tvw7oG01cgSzJo1g1qQxFdd5du16HljxEq9s7GTDpi5e6+hk3YbwWPNqB2te2chzL2+gK+d05py1r3Ww5tUOBsqoHq0tGbYb08b4LVppyWbIZkLAGDOyhdFtLYlgE+QDST4A9TynILAl18lmIJvpCUgZM9paMowbPYLxo9vYojXLiGyGlkxYlsnEIBe3lYxd3e/F7WfiwkymJ1gm8+4pE7S1ZBk5IsOITKZnHQVGGUaqdWWte3AA9geWu/sTAGa2iNCekQwOc4Dve6jS3G1mW5vZDu7+jwaUp6kmbT2KSVuPqinNpq4cL63fRFfOux85D3/zMcPdcYecQ/7dXC48d6c7uORf5zys5e4hTXwvl3M6unJ0dOZYv6mL9R1ddHTl6Mo5m7pyvPBKB6te2sDa9ZvI5ZzOXI7V6zbw2OpNvLaxC4fuebhDvrE03fkn3qO0XO7QFfdtIOsJcD2Bx0hExeS6iTQ975UGUSuTqDCAFW68XBBOJs/XHM2Kt1NYhuJ8ym0vny4Ta6zZjDEim6E1axXXLdqVstuvFmqTJxSbW7nc/hUut5Ll+ZpxW0u24ueQZnvV1s1mjDGjRjB21IjN3i+V9rSjXHn2mDyW9unjU24hvdRjK9XJZEJvp7wVlNYKyq0zGSgIDmY2F5gLMHXq1LoXdKAYkc0wccu2/i5GU3kMEF3u5HKhx9ja9Zt48dWNrO/IsakrR0dXrifQ5YNbURXLvTDwJINi4TqFgSqXczZ25tjYmaOzy3u2kShfwbYT6QvyT0ZFep7m0/e8Lk1TrbZYLsAm0xeWqXBfk59L+fQV9iV+vjmHzlyOjs5wwlC86uZ6PyY/52rrlPtMqm2vYtkTn0Fyn1/eEE5oNnbmKpa7XK6Vdq9cGTd1OS+v39TwYXnCDbuDPziUC5DFn1yadXD3hYRRYmlvbx/Yp5pSE4uXlPJfzlGtWcaNbmXGxNFV04kMNO7Oax1d1QNEyqNXpSDZ1pLtRck2r9nBYQUwJfF6R+DZXqwjIjLgmRmj25p9mK2PZo8HsQSYaWYzzKwV+CCwuGidxcCHLXgT8NJQaG8QERlMmhrS3L3TzOYDtxG6sl7j7svMbF5cvgC4hdCNdTmhK+tHm1lGERFp/mUl3P0WQgBIvrcg8dyBM5pdLhER6aFhRkVEpISCg4iIlFBwEBGREgoOIiJSoqbJfgYqM3seeKrGZBMJs9g1Mk0z8hjIaQZquZqVZqCWqzdpBmq5mpVmoJarr6a5+zZll4Rb+YffA1ja6DTNyGMgpxmo5dL+D+99GWr736iHLiuJiEgJBQcRESkxnIPDwiakaUYeAznNQC1Xs9IM1HL1Js1ALVez0gzUcjXMkGiQFhGR+hrONQcREalAwUFEREooOAxD1qTJkJuRj/ZleOfTrH0ZjoZNcDCz3czsQDMbYWappk4ys3eb2Vl1yDvVF9jMappg2symmFmrmY2Orzf7/zSzA4CDBlo+Q2lfepPPUNqX3uTTrH2ph+ES9IZFcDCz9wK/AP4N+B5whpmN2UyadwAXAQ/1Ir8DzOwwM9sPwjDkm/tnm9k7gflmNjJlHkcDtwL/DlxrZru5e67ajyrm8R/Ahhr2peH5DKV96U0+Q2lfepNPs/alKH1rnHCsljR7m9kkr6EXT6359CaPhunvu/Aa/QBGAD8CDo6vjwO+SggUYyqkOQh4Dtg/vh4LTAO2SJHfkcBjhC5pPwe+l1hmVdLcDxxeZpkVvyZMo/o34HBgO+DThKlUd4/rZMps5xBgJXBEfL1l/DuqXJpm5DOU9iWRZjLwYNp84nft2Rrz2AFYVuO+vAn4x0D6zJr5fylKfxzwY+DXwNHAuBS/63cCd+fLleZRaz69yaORj34vQMN3MASHW4FT8l8c4DDgMmAeZQ7YwG6EuaznABOA3xImKLoJeF+5NDFdFlgEfCi+HgP8AfhxYp3ig/0s4O/A3Ph6Qsx/jyppsoTgMzm/DDgz/mB2rVC2T8by70kIdDcAC4CbgZlV8llQYz6fiJ9BqnziAeJqYFINeXwc+AmwR9p9ie8t7EU+N6XNBxgFtAHfSZNP/H6cCdxYQx6TgK3S5hGXTQc+U0s+id/K5YR53Gv5/18P7JVyf5ryXU6k3RX4X+BA4ATCtMRnATtXOYa8C3gA2KfatvuST2/yaPSjXzNv2k7C2+M/59DEF/LE+CWu9CXaC3iCECROjz+UU+MPbHyVvM4lBofEe78Hrqqw/r7AlcDHgNnAbwg1nduBfy9adxdgP0IA+RFwTtHyc4DrgJGJH9ouhAC0PfApwkFlRfwB7g98ljBt61aJ7ewOHAHMiPmclyKfN8Sy7RrzuapaPoSzvw/H598HPp8ij0OB98bnnyBcItzcvrwb+GfCScIi4F9T5HNM/J9vQfhBfzdFPnOAKxKf2fnV8gHeQzhByX9eafLIn1nuQbikkuYzeydwB7AP4WTomhT5vAn4MPBW4GfAuSnyOZBwpjwb+Bc28z0DZhK+L2MIB/WzUuSxK+G7PAE4G/gmoTZUcV/K/N4OAO5MvD4wfvb/VC4d4Xd/FfBofL0lcCnhu/duYGSFfPZPm0/8PtScR8OPm/2RadN3MnzB5hPOUN6ceP+/gTdWSTcLOKPovV8VpyFxhgOcTLisMDXx3kRC9XJWhTQHxy/64/EHnK9u/4aegJY/s7iLcDZ3DPAk8NnEdqaTCEKJNL+LX8yD45dzbmKdHQkHjNb4+siYZjHhoH0oYcTb86rkk0yzKH5uZwGnl8mnLX75lwEPA+8n/Nj/DnyuXB7xB5pP8whwcnx/PvCJKvvyDuA+4J2JbT5N4mBXZl/yaWbH11sSDt4fq5LPYXFf8vlMjZ/Z2RX2J79+Po/RhAPcR1Lsy9PABcC4mEeafXka+HJ878wK/5d8PsfE/+UPCAes2YTv2TlV8smnuZ5wQN8v5nNauXwIgfF+QuC5APg68BLwySp55NP8HPgy8K8x7fGV9qXK7/r7wAeAlvj6IMLVhXdUWH8E4Td3N/AXQvCbD9wJvK9Cmixwbdp8CLXOb9WSR6Mf/X7gbtqOhh/TGfGfMxf4COFgs10N2zgOuCeZhnAAfg1YlHjvIuAZCgPEIuCAKmn2B44tyu86wlncQYSDyd7x/YWENpNJhB/+5wg1hFOApXFfi9MsINZEgLZEHifFL+DWhOu+j9LT1vKfhAP9zoTrwGcTzt6S+RSnWUw4S2oh0UaTzCe+PodwffmG+APKxs/sLMJZZXceiW3k01xPz2W4SvtS3G40MZZpH8LZZrl9KU4zPqabAIyusi9nA5+Jz6fGz+xDwDrCJZDdivJJrr9jzPcwCr9XyX15G7CcUKNrJZzU7Ez4n6+g/P+/OM1vCLXUESTORIvymUA4835DXPb9WLZDgDWEA37xZ1ac5jrgKMLJzbgy+cwg/AZnxffnEjqL/IAQID5N0f8/5pFMc3rc1r8B21T6vyTePyB+vvn/66mEA/HhwIj43kcIl6paEmkOz6eJ7/0AuCDx+kTC9z2fZkxiWYZwcP9apXwoavMknMReWy2PZj5aGCbc/f/M7LuE3kcfJ/RyONndn9tc2tjT6KOE67bvz6eJ3e7mE84sDzKzG939BHf/fOyc9J9mdiXhALMXsLpMmhvc/UR3/59kV1YzO47ww/4H4Xrspe5+b1x8PnCduz9rZocTDg5nEwLMR+O+UpTm88D3zKzV3TfGPE4j/OBPdPe1ZvYc8PFYlu2BdkLj/f8Q2gX2Jfxw2xP5FKfZj1C9fxa428xuJBwo5wMnufvaWJ5OwoH0e4Ta0hTgT8De8bPaI59H4l+RT3MtcLqZ7QZ0mNn5cRtz83mY2RpgE7CDmU0gXLroJJwQVNqX4jQ/BjYSDlq/MrMfEi63lNuXfI+URXHfHyc0tL6DEBwOSuSTXP8mQoDvADJmdibh5OHsxL5kCZfglpnZ1nEfjnL3fzezw+L//zNxn/J5FKf5X8LJyT0xf8zsdMIJUz6fsYQz2NeZ2dOEWuM2hJrwbfH1roQDZz6f4jSHEb7va4EnzewrhHa6swgH7xcJtbHtgYfcfWHsrfQg4WRmFvA64I1FeSTTfNfMZsf33gbcaGbz4ncg+X/BzI4E/h+h3XA7M3vK3c80s/MItZEphIO+E44JXpRmWzN70d1PdfcPmVnymNlKCJoee0R+wczmEobd7jKz6wiXmd9VJp/3AJ+P6y9x95y7bzCzefnfZ3EeNFuzo9FAeBDOUqv2aCha3wjR/3Vllk0ifEnzl45uTCw7lnBt/GrimVWFND8s2uZHgCX0nI1liWcZ8fmOwL3ADvG9aYQzkbFF+1guzTbxvZ2Ab5Tbp7j8fOJlHsKZ2neA6fF12V4XRWk+SjhQ7gxcAry+aN2diZeqCGeLm4CLEstL8iiT5jXgivj6y2Xy2IvSdqO5hLaBKeXyqZDmVEINZ0aFfXkD4XLXIsIBDcJB9BJgTnE+FdbfiVC7e29MN6vM/mfi39nAKnpqhSPj361TpNkjvh5NaPMo3pf3EWrHdxPbNAgB7hv01HyLP7Nyad5CCOIHAxdTeEl1HuFA+aH4f/shIUh9LbHO1kV5FKe5nnCS9724/Ctl9qVcB5E/A9fE1yfH7dxJCOR7V0hT0Kkk8f1eGv+X0+M6t8e07fTUJrYkfOeuS+RzVJn1y/XK6s6jt8e6vjz6/UA9lB6E6u9PiAGCcOY/LWWa6+Pr1xMuRexUYf2W+IW7I74+mXBteFSVPMql+QoVuvJW2MatQHt8nqonRUyzS4Vlk+LB43RC198vAL8ktiGUy6NMmgtimhMqlYny7Ua3UaVXSJU0Zf8ncfm7Ce0mFybe+x49je7FPYEqrX9Mys/2QsJ19ywpLznENJ8FsvF12RMkwqWcrwLvSrz3M+A9VT6zSmkOL7PuWEIt4lrgm4n3b6FMgNtcmvg3WyFduQ4ifyraxh7AtptJ092phFDj/C49gXYqcFh8fgHhMlA78ZInPQH6jcC2VdbPBxSLeVxDotdisx/9kulQfhBqA9cSzgyXAzvWmOZRYo1gM2muI5xh3pP2C1SUZs8q6xUfyPJtLdv3Ik3FfYkHq6eBd8fXRxDP6OuZpkK5am1r+utm9r+FcMnpCeC0+FhK5a6LldYvG0wrlOkPlQ6Km0mz2WBC6GRwLaHWcEzc/+m9SDOjyvrJex4+TDhoj95MHuXSbFm0TpoOIj+hsDaftlPJbvF/t0VRmrGJ558ntNftF1/vVSaPauvn21YqnvA149FvGQ/lB6HrZHcVvp5pCGcVrYRr2k8T+3XXO01M1xYPWstIWbWtJQ3hOuy+idebvdTXmzSJz+BUQptTqpuMeplmH8JllK+n+f/Xun5R2ps2d8DubRpCA/WZhN5xt+UPcPVOE9PlP+Nafi9l01C/DiKV0rypKE3yMnJr4vnnCZciLyX05DqphvUfJNHQ3l8PzedQZ2Y2jvAD/LS7P9DANKcQGrKW1VC2mtKY2QjCPSKPu/sjDUxjXuMXsdY0sVPBYcAqd3+4UWmaoRmfVyLdVoRa4cuNSmNm0wi9eZbXkEdJmtjZ4yfATwkdANrc/YS47CJCbSbfQeRkwrX/1XVI0+LuJ8c0bd7T4eNOQtvTewg13rTrv9Pd/5b2s2gUBYcGMLOR7l7TmC+1pmnmAUJksDCzScDLhG6hC4BNiYP9sYQeT/sC33L3B+uYZkP+gB+X70q4GfIUd7+/1vUb8dnUSsFBRIak2B15IdDh7ieY2e7AK+7+VIPSrHf3k83sjYReTg+5+wt9Xb+/DItRWUVk+HH3NcR7mszsEcLNdl0NTLPJzB4m3FOzvNKBvtb1+4uCg4gMWfGA+wChK+yx7r6iwWm2Joz/9Ww91+8PCg4iMmTFzh5HEcYzStXI24w0vcmj2dTmICJDWjM6iPQmTW/yaCYFBxERKaHLSiIiUkLBQURESig4iIhICQUHkQrM7Itm5onHKjP7pZnt2aD87jSzHzdi2yK1UnAQqe4lwsx2BxImaNoVuN3MxvdnoUQabdjMBCfSS53ufnd8freZPUmYMGY2YRRNkSFJNQeR2uQHRZsCYGYHmtliM3vWzF41s/vM7KRkAjM7JV6W2sPMbo/rPRynlqzIzMaa2R/N7H4z26ZB+yNSloKDSG2mxr9/j3+nAX8EPkaY3e0nwLVmdkKZtDcQZv06ljCT3SIz27FcJvGy1W8I83Ac4e7P120PRFLQZSWRzUhMKj8NuBy4jzAgG+6+KLGeAb8jzNd9OnBj0aa+6e7XxHXvAZ4jTBqzoCi/bQiB4RXgyFrmUhCpFwUHkeomAJsSr9cQpnPMT9AyDvgSMAeYTJjTGWBlmW39Ov/E3deY2WpCIEnajjCT2irCVKiv1mMnRGqly0oi1b0E7Ae8iTDMcitwg5nlfzvXAccDXyXMnbwfYWL4kWW2tbbodUeZ9WYBrwd+oMAg/Uk1B5HqOt19aXz+FzNbD3wfeL+Z/QI4Gpjv7t2XhhKBozd+C9wLLDSzF9z9P/uwLZFeU81BpDbXA8uAc4E2wmWkjfmFcf7kY/qSgbt/Gfg6cLOZvaUv2xLpLdUcRGrg7m5mFwM/BNqBJcAFZvYykAPOI1yKGtPHfM6LgeYXZvb2xL0WIk2hmoNI7X5E6Ip6DnAioVvr94FvE7qyfr9O+cyP27vVzPaq0zZFUtF8DiIiUkI1BxERKaHgICIiJRQcRESkhIKDiIiUUHAQEZESCg4iIlJCwUFEREooOIiISAkFBxERKfH/AUY7j81nRw/3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 利用奇异值分解确定降维\n",
    "\n",
    "data2 = data1.copy(deep=True)\n",
    "x0 = np.array(data2)\n",
    "x0 = x0[:,:-1]\n",
    "m,n = x0.shape\n",
    "## 奇异值分解\n",
    "U,S,V = np.linalg.svd(x0)  \n",
    "print(U.shape,S.shape,V.shape)\n",
    "S_list = list(S)\n",
    "## 奇异值求和\n",
    "S_sum = sum(S)\n",
    "##奇异值序列归一化\n",
    "S_normalization_list = [x/S_sum for x in S_list]\n",
    "\n",
    "X = []\n",
    "for i in range(len(S_normalization_list)):\n",
    "    X.append(i+1)\n",
    "\n",
    "fig1 = plt.figure().add_subplot(111)\n",
    "fig1.plot(X,S_normalization_list)\n",
    "# fig1.set_xticks(X)\n",
    "fig1.set_xlabel('Rank',size = 15)\n",
    "plt.xticks(range(0,len(X),5)) #每5个点显示一次\n",
    "# 下面的rotation表示的是旋转角度\n",
    "plt.xticks(rotation = 45)\n",
    "fig1.set_ylabel('Normalize singular values',size = 15)\n",
    "plt.savefig(\"svd.pdf\",bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 11),\n",
       " array([[-379.47605774,  -21.65416422,   -2.62315497, ...,   -1.19980795,\n",
       "           -5.9790927 ,    5.23488439],\n",
       "        [-338.1008312 ,   26.74641786,   -6.98812817, ...,    9.823755  ,\n",
       "           -5.97096435,   -2.38774293],\n",
       "        [-385.48433733,  -28.99251544,    1.4644935 , ...,    4.69800793,\n",
       "            8.25225297,   -1.68722445],\n",
       "        ...,\n",
       "        [-348.39401306,   31.1570448 ,    7.57428453, ...,    4.0153582 ,\n",
       "           -6.03981423,    5.07525527],\n",
       "        [-382.70228722,  -27.50288351,    7.07418145, ...,   -1.80960099,\n",
       "           -6.76726038,    4.00209693],\n",
       "        [-348.09236284,   -4.2206452 ,   16.61340853, ...,   -3.06355578,\n",
       "           -8.68532443,    2.48388323]]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 数据重构\n",
    "k = 11 ## 保留的奇异值阶数11\n",
    "V_T_kxn = V[:k,:]\n",
    "\n",
    "reduceNoiseMat = np.array(np.dot(V_T_kxn, np.mat(x0).T).T)\n",
    "reduceNoiseMat.shape, reduceNoiseMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-379.476058</td>\n",
       "      <td>-21.654164</td>\n",
       "      <td>-2.623155</td>\n",
       "      <td>26.853231</td>\n",
       "      <td>25.472097</td>\n",
       "      <td>-19.615445</td>\n",
       "      <td>1.338796</td>\n",
       "      <td>-11.448556</td>\n",
       "      <td>-1.199808</td>\n",
       "      <td>-5.979093</td>\n",
       "      <td>5.234884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-338.100831</td>\n",
       "      <td>26.746418</td>\n",
       "      <td>-6.988128</td>\n",
       "      <td>25.285657</td>\n",
       "      <td>7.297526</td>\n",
       "      <td>-19.543693</td>\n",
       "      <td>-3.419809</td>\n",
       "      <td>-3.803454</td>\n",
       "      <td>9.823755</td>\n",
       "      <td>-5.970964</td>\n",
       "      <td>-2.387743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-385.484337</td>\n",
       "      <td>-28.992515</td>\n",
       "      <td>1.464493</td>\n",
       "      <td>-4.127039</td>\n",
       "      <td>-19.721764</td>\n",
       "      <td>-16.345585</td>\n",
       "      <td>7.280149</td>\n",
       "      <td>-7.385921</td>\n",
       "      <td>4.698008</td>\n",
       "      <td>8.252253</td>\n",
       "      <td>-1.687224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-350.582763</td>\n",
       "      <td>-15.267897</td>\n",
       "      <td>-12.967149</td>\n",
       "      <td>18.741302</td>\n",
       "      <td>23.021877</td>\n",
       "      <td>2.314732</td>\n",
       "      <td>-2.749612</td>\n",
       "      <td>3.702500</td>\n",
       "      <td>1.554905</td>\n",
       "      <td>14.881587</td>\n",
       "      <td>4.143999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-372.771322</td>\n",
       "      <td>-21.401662</td>\n",
       "      <td>-9.955029</td>\n",
       "      <td>-16.747700</td>\n",
       "      <td>28.084089</td>\n",
       "      <td>17.320850</td>\n",
       "      <td>-8.393350</td>\n",
       "      <td>-3.238443</td>\n",
       "      <td>-9.912459</td>\n",
       "      <td>10.873626</td>\n",
       "      <td>2.909371</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-370.952430</td>\n",
       "      <td>2.854775</td>\n",
       "      <td>-1.045087</td>\n",
       "      <td>5.746846</td>\n",
       "      <td>14.476716</td>\n",
       "      <td>-1.367972</td>\n",
       "      <td>5.085759</td>\n",
       "      <td>-6.805689</td>\n",
       "      <td>-3.357961</td>\n",
       "      <td>1.048650</td>\n",
       "      <td>-2.907645</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-382.646221</td>\n",
       "      <td>-24.977591</td>\n",
       "      <td>-1.556585</td>\n",
       "      <td>-11.295939</td>\n",
       "      <td>16.463789</td>\n",
       "      <td>-8.465985</td>\n",
       "      <td>10.101894</td>\n",
       "      <td>13.130806</td>\n",
       "      <td>4.984767</td>\n",
       "      <td>2.124277</td>\n",
       "      <td>-8.034119</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>-348.394013</td>\n",
       "      <td>31.157045</td>\n",
       "      <td>7.574285</td>\n",
       "      <td>3.701310</td>\n",
       "      <td>-3.552685</td>\n",
       "      <td>21.302643</td>\n",
       "      <td>14.538086</td>\n",
       "      <td>2.090994</td>\n",
       "      <td>4.015358</td>\n",
       "      <td>-6.039814</td>\n",
       "      <td>5.075255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>-382.702287</td>\n",
       "      <td>-27.502884</td>\n",
       "      <td>7.074181</td>\n",
       "      <td>22.460883</td>\n",
       "      <td>14.854184</td>\n",
       "      <td>-15.332829</td>\n",
       "      <td>12.368336</td>\n",
       "      <td>5.636382</td>\n",
       "      <td>-1.809601</td>\n",
       "      <td>-6.767260</td>\n",
       "      <td>4.002097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-348.092363</td>\n",
       "      <td>-4.220645</td>\n",
       "      <td>16.613409</td>\n",
       "      <td>1.064560</td>\n",
       "      <td>3.687603</td>\n",
       "      <td>12.309400</td>\n",
       "      <td>-8.958850</td>\n",
       "      <td>10.187535</td>\n",
       "      <td>-3.063556</td>\n",
       "      <td>-8.685324</td>\n",
       "      <td>2.483883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    -379.476058 -21.654164  -2.623155  26.853231  25.472097 -19.615445   \n",
       "1    -338.100831  26.746418  -6.988128  25.285657   7.297526 -19.543693   \n",
       "2    -385.484337 -28.992515   1.464493  -4.127039 -19.721764 -16.345585   \n",
       "3    -350.582763 -15.267897 -12.967149  18.741302  23.021877   2.314732   \n",
       "4    -372.771322 -21.401662  -9.955029 -16.747700  28.084089  17.320850   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "9995 -370.952430   2.854775  -1.045087   5.746846  14.476716  -1.367972   \n",
       "9996 -382.646221 -24.977591  -1.556585 -11.295939  16.463789  -8.465985   \n",
       "9997 -348.394013  31.157045   7.574285   3.701310  -3.552685  21.302643   \n",
       "9998 -382.702287 -27.502884   7.074181  22.460883  14.854184 -15.332829   \n",
       "9999 -348.092363  -4.220645  16.613409   1.064560   3.687603  12.309400   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  feature_10  label  \n",
       "0      1.338796 -11.448556  -1.199808  -5.979093    5.234884      0  \n",
       "1     -3.419809  -3.803454   9.823755  -5.970964   -2.387743      0  \n",
       "2      7.280149  -7.385921   4.698008   8.252253   -1.687224      0  \n",
       "3     -2.749612   3.702500   1.554905  14.881587    4.143999      2  \n",
       "4     -8.393350  -3.238443  -9.912459  10.873626    2.909371      2  \n",
       "...         ...        ...        ...        ...         ...    ...  \n",
       "9995   5.085759  -6.805689  -3.357961   1.048650   -2.907645      1  \n",
       "9996  10.101894  13.130806   4.984767   2.124277   -8.034119      3  \n",
       "9997  14.538086   2.090994   4.015358  -6.039814    5.075255      0  \n",
       "9998  12.368336   5.636382  -1.809601  -6.767260    4.002097      0  \n",
       "9999  -8.958850  10.187535  -3.063556  -8.685324    2.483883      0  \n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3 = pd.DataFrame()\n",
    "for i in range(reduceNoiseMat.shape[1]):\n",
    "    data3[datanames[i]] = list(reduceNoiseMat[:,i])\n",
    "data3[names[-1]] = data2[names[-1]]\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_0    -307.493784\n",
      "feature_1      58.359089\n",
      "feature_2      42.246231\n",
      "feature_3      39.113488\n",
      "feature_4      33.256863\n",
      "feature_5      26.585818\n",
      "feature_6      25.126207\n",
      "feature_7      24.129647\n",
      "feature_8      26.970696\n",
      "feature_9      18.094795\n",
      "feature_10     25.175043\n",
      "label           3.000000\n",
      "dtype: float64\n",
      "feature_0    -400.276569\n",
      "feature_1     -55.981369\n",
      "feature_2     -40.862425\n",
      "feature_3     -37.125049\n",
      "feature_4     -31.039385\n",
      "feature_5     -29.915214\n",
      "feature_6     -24.997641\n",
      "feature_7     -26.332257\n",
      "feature_8     -23.814017\n",
      "feature_9     -18.425411\n",
      "feature_10    -21.266271\n",
      "label           0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# (data2['feature_1']).describe()\n",
    "print(np.max(data3))\n",
    "print(np.min(data3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来不错，预处理到这里就可以了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练测试数据集\n",
    "def split_train_test(data, test_ratio):\n",
    "    np.random.seed(46)\n",
    "    shuffled_indices = np.random.permutation(len(data))  # 生成和原数据等长的无序索引\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train,test = split_train_test(data3, 0.1)\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanames = data3.columns.drop('label')\n",
    "X_train,X_test = train[datanames],test[datanames]\n",
    "y_train,y_test = train['label'],test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred,test):\n",
    "    cnt = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == test[i]:\n",
    "            cnt += 1\n",
    "    return cnt/len(pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多分类逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegresion(object):\n",
    "    def __init__(self,max_iter=1000,learning_rate=0.1):\n",
    "        self.w = None\n",
    "        self.max_iter = max_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "    def softmax(self, a):\n",
    "        # 处理一下溢出\n",
    "        c = np.max(a)\n",
    "        exp_a = np.exp(a-c)#溢出对策\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        y = exp_a/sum_exp_a\n",
    "        return y\n",
    "    \n",
    "    def model(self, X, theta):\n",
    "        return self.softmax((X@theta))\n",
    "    \n",
    "    def gradient(self, X, y, theta):\n",
    "        # 梯度计算函数\n",
    "        grad = np.zeros(X.shape[1])\n",
    "        error = (self.model(X, theta)- y)\n",
    "        grad = np.dot(X.T, error)/len(X)\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    # def cost(self, X, y, theta):\n",
    "    #     # 利用对数似然计算损失\n",
    "    #     left = np.multiply(-y, np.log(self.model(X, theta)))\n",
    "    #     right = np.multiply(1 - y, np.log(1 - self.model(X, theta)))\n",
    "    #     return np.sum(left - right) / (len(X))\n",
    "\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        X = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "        self.n_classes = len(Y)\n",
    "        W = np.zeros((np.size(X, 1), self.n_classes))\n",
    "        t0 = time.time()\n",
    "        for _ in tqdm(range(self.max_iter), desc='Processing'):\n",
    "            # print(W)\n",
    "            W_prev = np.copy(W)\n",
    "            Y_hat = self.softmax(X @ W)\n",
    "            grad = self.gradient(X,Y,W)\n",
    "            W -= self.learning_rate * grad\n",
    "            if np.allclose(W, W_prev, rtol=1e-3):\n",
    "                t1 = time.time()\n",
    "                # print()\n",
    "                break\n",
    "            t1 = time.time()\n",
    "        self.w = W\n",
    "        print(\"一共用时：\"+str(t1-t0)+\"s\")\n",
    "\n",
    "    def predict_prob(self,X):\n",
    "        X = np.hstack([X,np.ones((X.shape[0],1))])\n",
    "        pred_y = self.softmax((X @ self.w)/np.max(X @ self.w))\n",
    "        return pred_y\n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.argmax(self.predict_prob(X),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [08:08<00:00,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共用时：488.5729990005493s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegresion(max_iter=100)\n",
    "model.fit(np.array(X_train), np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.249"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "acc(pred, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[390242.98052586, 390242.98052586, 390242.98052586, ...,\n",
       "         130080.99559893, 130080.99559893, 390242.98052586],\n",
       "        [370495.61544212, 370495.61544212, 370495.61544212, ...,\n",
       "         123498.54044521, 123498.54044521, 370495.61544212],\n",
       "        [388376.99182942, 388376.99182942, 388376.99182942, ...,\n",
       "         129458.99934003, 129458.99934003, 388376.99182942],\n",
       "        ...,\n",
       "        [353177.02704711, 353177.02704711, 353177.02704711, ...,\n",
       "         117725.67754382, 117725.67754382, 353177.02704711],\n",
       "        [387802.7677692 , 387802.7677692 , 387802.7677692 , ...,\n",
       "         129267.59132123, 129267.59132123, 387802.7677692 ],\n",
       "        [377280.53686232, 377280.53686232, 377280.53686232, ...,\n",
       "         125760.18096303, 125760.18096303, 377280.53686232]]),\n",
       " array([[1.71734129e-07, 1.71734129e-07, 1.71734129e-07, ...,\n",
       "         8.95298103e-08, 8.95298103e-08, 1.71734129e-07],\n",
       "        [1.63449718e-07, 1.63449718e-07, 1.63449718e-07, ...,\n",
       "         8.80663883e-08, 8.80663883e-08, 1.63449718e-07],\n",
       "        [1.70933669e-07, 1.70933669e-07, 1.70933669e-07, ...,\n",
       "         8.93904929e-08, 8.93904929e-08, 1.70933669e-07],\n",
       "        ...,\n",
       "        [1.56513819e-07, 1.56513819e-07, 1.56513819e-07, ...,\n",
       "         8.68026578e-08, 8.68026578e-08, 1.56513819e-07],\n",
       "        [1.70688094e-07, 1.70688094e-07, 1.70688094e-07, ...,\n",
       "         8.93476642e-08, 8.93476642e-08, 1.70688094e-07],\n",
       "        [1.66250059e-07, 1.66250059e-07, 1.66250059e-07, ...,\n",
       "         8.85664824e-08, 8.85664824e-08, 1.66250059e-07]]),\n",
       " (1000, 9000))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_prob = model.predict_prob(np.array(X_test))\n",
    "predict_prob\n",
    "X=np.array(X_test)\n",
    "X=np.hstack([X,np.ones((X.shape[0],1))])\n",
    "def softmax(a):\n",
    "\tc = np.max(a)\n",
    "\texp_a = np.exp(a - c) # 溢出对策\n",
    "\tsum_exp_a = np.sum(exp_a)\n",
    "\ty = exp_a / sum_exp_a\n",
    "\treturn y\n",
    "X@model.w,softmax((X@model.w)/np.percentile(X@model.w,95)),(softmax(X@model.w)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节点\n",
    "class Node(object):\n",
    "    def __init__(self, feature_index=None, threshold=None, value=None, left_tree=None, right_tree=None):\n",
    "        self.feature_index = feature_index  # 特征下标\n",
    "        self.threshold = threshold          # 划分临界点\n",
    "        self.value = value                  # 叶节点权重(只有叶节点有)\n",
    "        self.left_tree = left_tree          # 左子树：小于临界值\n",
    "        self.right_tree = right_tree        # 右子树：大于临界值\n",
    "\n",
    "\n",
    "# 参数说明：最小划分样本数，最小划分增益，最大深度，gamma,lambda\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, min_samples=5, min_split_gain=1e-7, max_depth=4, gamma=0, lam=1):\n",
    "        self.min_samples = min_samples\n",
    "        self.min_split_gain = min_split_gain\n",
    "        self.max_depth = max_depth\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.root = None\n",
    "\n",
    "    def gradient(self, y, y_pre):\n",
    "        \"一阶导\"\n",
    "        return -2*(y - y_pre)\n",
    "\n",
    "    def hess(self, y, y_pre):\n",
    "        \"二阶导\"\n",
    "        return 2*np.ones_like(y)\n",
    "\n",
    "    def split(self, y):\n",
    "        \"传入回归树的 y 有2列，第一列为真实值，第二列为预测值\"\n",
    "        y_true = y[:,:1]\n",
    "        y_pre = y[:,1:]\n",
    "        return y_true, y_pre\n",
    "\n",
    "    def obj(self, y, y_pre, gamma, lam):\n",
    "        \"节点得分\"\n",
    "        G = self.gradient(y, y_pre).sum()\n",
    "        H = self.hess(y, y_pre).sum()\n",
    "        return -0.5*(np.power(G,2)/(H+lam))+gamma\n",
    "\n",
    "    def gain(self, y, y_left, y_right, gamma, lam):\n",
    "        \"收益\"\n",
    "        y, y_pre = self.split(y)\n",
    "        y_left, y_left_pre = self.split(y_left)\n",
    "        y_right, y_right_pre = self.split(y_right)\n",
    "        obj_1 = self.obj(y, y_pre, gamma, lam)\n",
    "        obj_1_left = self.obj(y_left, y_left_pre, gamma, lam)\n",
    "        obj_1_right = self.obj(y_right, y_right_pre, gamma, lam)\n",
    "        obj_2 = obj_1_left + obj_1_right\n",
    "        return obj_1 - obj_2\n",
    "\n",
    "    def leaf_value(self, y, lam):\n",
    "        \"计算叶节点权重\"\n",
    "        y, y_pre = self.split(y)\n",
    "        G = self.gradient(y, y_pre).sum()\n",
    "        H = self.hess(y, y_pre).sum()\n",
    "        return -G/(H+lam)\n",
    "\n",
    "    def divide(self, X, feature_index, threshold):\n",
    "        \"按某个特征的某个值划分为左右两部分,小的在左,大的在右\"\n",
    "        split = lambda sample: sample[feature_index] < threshold\n",
    "        X_left = np.array([sample for sample in X if split(sample)])\n",
    "        X_right = np.array([sample for sample in X if not split(sample)])\n",
    "        return X_left, X_right\n",
    "\n",
    "    def build_tree(self, X, y, current_depth=0):\n",
    "        \"构造决策树。注：这里的y是(m,2)维：第一列为真实值，第二列为预测值\"\n",
    "        #初始化最大收益、最好的划分及划分后的左右子树的样本集合\n",
    "        largest_gain = 0\n",
    "        # 将y合并到 X 的最后一列：方便左右子集划分\n",
    "        Xy = np.concatenate((X, y), axis=1)\n",
    "        # m, n 分别为X的行与列数\n",
    "        m, n = np.shape(X)\n",
    "        # 贪心算法求解划分的特征\n",
    "        # 划分条件：\n",
    "        # (1) 节点分配到的样本数大于阈值; \n",
    "        # (2) 当前深度不大于最大深度要求;\n",
    "        # (3) 划分后的增益大于阈值\n",
    "        if m > self.min_samples and current_depth < self.max_depth:\n",
    "            # 遍历 X 中的特征\n",
    "            for feature_index in tqdm(range(n), desc='Processing'):\n",
    "                # 抽出某个特征下标 feature，合并该特征的相同数据，并对其进行由小到大的排序\n",
    "                sorted_feature_values = np.unique(X[:,feature_index])\n",
    "                # 以特征下标 feature 所在列排序后的每个值为临界点将样本划分为左右两个集合；\n",
    "                for each_value in sorted_feature_values:\n",
    "                    # 左小，右大\n",
    "                    Xy_left, Xy_right = self.divide(Xy, feature_index, each_value)\n",
    "                    # 当左右集合均不为空时进行，否则 continue\n",
    "                    if len(Xy_left) > 0 and len(Xy_right) > 0:\n",
    "                        # 左右集合所对应的标签,计算收益\n",
    "                        gain = self.gain(y, Xy_left[:,n:], Xy_right[:,n:], self.gamma, self.lam)\n",
    "                        # 记录最大收益的信息\n",
    "                        if gain > largest_gain:\n",
    "                            largest_gain = gain\n",
    "                            best_feature_index = feature_index\n",
    "                            threshold = each_value\n",
    "                            left = Xy_left\n",
    "                            right = Xy_right\n",
    "        # 划分后增益大于阈值则继续划分\n",
    "        if largest_gain > self.min_split_gain:\n",
    "            # 构造左右子树\n",
    "            left_tree = self.build_tree(left[:,:n], left[:,n:], current_depth+1)\n",
    "            right_tree = self.build_tree(right[:,:n], right[:,n:], current_depth+1)\n",
    "            return Node(feature_index=best_feature_index, threshold=threshold, left_tree=left_tree, right_tree=right_tree)\n",
    "        # 计算叶节点的权重\n",
    "        leaf_value = self.leaf_value(y, self.lam)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"开始构造树，根节点指向树根\"\n",
    "        t0 = time.time()\n",
    "        self.root = self.build_tree(X, y)\n",
    "        print(\"一共用时：\"+str(time.time()-t0)+\"s\")\n",
    "\n",
    "    def predict_value(self, X, node=None):\n",
    "        \" X 是测试集的一行数据。此函数递归到叶节点，并返回叶节点的权重，作为预测值\"\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        # 若有节点值，则返回节点权重作为测试集的预测值\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        # 与树的当前特征节点的临界值进行比较，小则进入左子树，大则进入右子树\n",
    "        feature_value = X[node.feature_index]\n",
    "        if feature_value < node.threshold:\n",
    "            return self.predict_value(X, node.left_tree)\n",
    "        else:\n",
    "            return self.predict_value(X, node.right_tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"对于测试集，逐行进行预测\"\n",
    "        y_pre = []\n",
    "        for x in X:\n",
    "            y_pre.append(self.predict_value(x))\n",
    "        return np.array(y_pre).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 120/120 [53:52<00:00, 26.94s/it] \n",
      "Processing: 100%|██████████| 120/120 [02:07<00:00,  1.06s/it]\n",
      "Processing: 100%|██████████| 120/120 [00:05<00:00, 23.31it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 489.80it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1084.13it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1410.85it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1026.40it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 3115.89it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 2307.73it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:04<00:00, 28.22it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:03<00:00, 35.15it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:02<00:00, 42.05it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1587.78it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 845.01it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1263.17it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 3000.07it/s]\n",
      "Processing: 100%|██████████| 120/120 [01:21<00:00,  1.48it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:05<00:00, 21.35it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 810.63it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 827.77it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:04<00:00, 25.14it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 294.90it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:03<00:00, 37.53it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:03<00:00, 31.50it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:02<00:00, 44.31it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 495.86it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:21<00:00,  5.46it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:18<00:00,  6.40it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 359.28it/s]\n",
      "Processing: 100%|██████████| 120/120 [32:37<00:00, 16.31s/it]\n",
      "Processing: 100%|██████████| 120/120 [28:57<00:00, 14.48s/it]\n",
      "Processing: 100%|██████████| 120/120 [14:51<00:00,  7.43s/it]\n",
      "Processing: 100%|██████████| 120/120 [04:45<00:00,  2.38s/it]\n",
      "Processing: 100%|██████████| 120/120 [01:46<00:00,  1.13it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:34<00:00,  3.49it/s]\n",
      "Processing: 100%|██████████| 120/120 [02:26<00:00,  1.22s/it]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 84.84it/s]\n",
      "Processing: 100%|██████████| 120/120 [01:59<00:00,  1.01it/s]\n",
      "Processing: 100%|██████████| 120/120 [02:16<00:00,  1.13s/it]\n",
      "Processing: 100%|██████████| 120/120 [00:02<00:00, 45.00it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 61.32it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 1224.50it/s]\n",
      "Processing: 100%|██████████| 120/120 [01:39<00:00,  1.20it/s]\n",
      "Processing: 100%|██████████| 120/120 [01:14<00:00,  1.62it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:02<00:00, 59.74it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:04<00:00, 24.23it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 81.08it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 597.98it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 844.99it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 3077.00it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 131.33it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 902.27it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 210.90it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 80.50it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 3438.54it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 4287.67it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 87.72it/s]\n",
      "Processing: 100%|██████████| 120/120 [00:01<00:00, 94.32it/s] \n",
      "Processing: 100%|██████████| 120/120 [00:00<00:00, 4283.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共用时：9171.37307024002s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Tree = DecisionTree(max_depth=6)\n",
    "Y_train = np.concatenate((np.mat(y_train),np.mat(np.ones_like(y_train))),axis=0).T\n",
    "Tree.fit(np.array(X_train), np.array(Y_train))\n",
    "# np.mat(X_train).shape, np.mat(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.252"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.round(Tree.predict(np.array(X_test)))\n",
    "acc(np.array(pred), np.array(y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共用时：5.553001403808594s\n"
     ]
    }
   ],
   "source": [
    "netmodel = MPC(verbose=False,solver='sgd', alpha=1e-5, activation='tanh',hidden_layer_sizes=(11,32,64,32,4,2), max_iter=5000, tol=1e-5, learning_rate='adaptive')\n",
    "t0 = time.time()\n",
    "netmodel.fit(np.array(X_train), np.array(y_train))\n",
    "t1 = time.time()\n",
    "print(\"一共用时：\"+str(t1-t0)+\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.245"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = netmodel.predict(np.array(X_test))\n",
    "acc(np.array(pred), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "1.3862243682913666\n",
      "0.245\n",
      "softmax\n"
     ]
    }
   ],
   "source": [
    "print(netmodel.n_iter_)\n",
    "print(netmodel.loss_)\n",
    "print(netmodel.score(np.array(X_test), np.array(y_test)))\n",
    "print(netmodel.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 支持向量机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SVMModel(object):\n",
    "    \"\"\"\n",
    "    SVM model\n",
    "    \"\"\"\n",
    "    def __init__(self, max_iter=1000, kernel_type='linear', C=1.0, epsilon=0.00001):\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel_func_list = {\n",
    "            'linear': self._kernel_linear,\n",
    "            'quadratic': self._kernel_quadratic,\n",
    "        }\n",
    "        self.kernel_func = self.kernel_func_list[kernel_type]\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = None\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Training model\n",
    "        :param X_train: shape = num_train, dim_feature\n",
    "        :param Y_train: shape = num_train, 1\n",
    "        :return: loss_history\n",
    "        \"\"\"\n",
    "        n, d = X_train.shape[0], X_train.shape[1]\n",
    "        self.alpha = np.zeros(n)\n",
    "        # Iteration\n",
    "        for i in tqdm(range(self.max_iter), desc='Processing'):\n",
    "            diff = self._iteration(X_train, Y_train)\n",
    "            # if i % 100 == 0:\n",
    "            #     print('Iter %r / %r, Diff %r' % (i, self.max_iter, diff))\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        return np.dot(self.w.T, X.T) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        # return np.int64((np.dot(self.w.T, X.T) + self.b)>0)\n",
    "        return np.sign(np.dot(self.w.T, X.T) + self.b).astype(int)\n",
    "\n",
    "    def _iteration(self, X_train, Y_train):\n",
    "        alpha = self.alpha\n",
    "        alpha_prev = np.copy(alpha)\n",
    "        n = alpha.shape[0]\n",
    "        for j in range(n):\n",
    "            # Find i not equal to j randomly\n",
    "            i = j\n",
    "            for _ in range(1000):\n",
    "                if i != j:\n",
    "                    break\n",
    "                i = random.randint(0, n - 1)\n",
    "            x_i, x_j, y_i, y_j = X_train[i, :], X_train[j, :], Y_train[i], Y_train[j]\n",
    "            # Define the similarity of instances. K11 + K22 - 2K12\n",
    "            k_ij = self.kernel_func(x_i, x_i) + self.kernel_func(x_j, x_j) - 2 * self.kernel_func(x_i, x_j)\n",
    "            if k_ij == 0:\n",
    "                continue\n",
    "            a_i, a_j = alpha[i], alpha[j]\n",
    "            # Calculate the boundary of alpha\n",
    "            L, H = self._cal_L_H(self.C, a_j, a_i, y_j, y_i)\n",
    "            # Calculate model parameters\n",
    "            self.w = np.dot(X_train.T, np.multiply(alpha, Y_train))\n",
    "            self.b = np.mean(Y_train - np.dot(self.w.T, X_train.T))\n",
    "            # Iterate alpha_j and alpha_i according to 'Delta W(a_j)'\n",
    "            E_i = self.predict(x_i) - y_i\n",
    "            E_j = self.predict(x_j) - y_j\n",
    "            alpha[j] = a_j + (y_j * (E_i - E_j) * 1.0) / k_ij\n",
    "            alpha[j] = min(H, max(L, alpha[j]))\n",
    "            alpha[i] = a_i + y_i * y_j * (a_j - alpha[j])\n",
    "        diff = np.linalg.norm(alpha - alpha_prev)\n",
    "        return diff\n",
    "\n",
    "    def _kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "\n",
    "    def _kernel_quadratic(self, x1, x2):\n",
    "        return np.dot(x1, x2.T) ** 2\n",
    "\n",
    "    def _cal_L_H(self, C, a_j, a_i, y_j, y_i):\n",
    "        if y_i != y_j:\n",
    "            L = max(0, a_j - a_i)\n",
    "            H = min(C, C - a_i + a_j)\n",
    "        else:\n",
    "            L = max(0, a_i + a_j - C)\n",
    "            H = min(C, a_i + a_j)\n",
    "        return L, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSVM(object):\n",
    "    def __init__(self, max_iter=1000, kernel_type='linear', C=1.0, epsilon=0.00001):\n",
    "        self.max_iter = max_iter\n",
    "        self.kernel_type = kernel_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = None\n",
    "        \n",
    "    def randrow(self, x):\n",
    "        return np.random.permutation(x)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        输入训练的数据，将y拆分，用1v1来最后确定多个svm模型\n",
    "        返回\n",
    "        \"\"\"\n",
    "        # 合并训练数据\n",
    "        ynew = np.mat(y).T\n",
    "        X = np.array(X)\n",
    "        data = np.concatenate((X,ynew), axis=1)\n",
    "        data = np.array(data)\n",
    "        \n",
    "        # 提取每个特征值训练集\n",
    "        feature = np.unique(data[:,-1])\n",
    "        self.feature = feature\n",
    "        data0 = []\n",
    "        for f in feature:\n",
    "            data0.append(data[data[:,-1]==f])\n",
    "            \n",
    "        # 组成两两之间的二分类一共 k(k-1)/2\n",
    "        train = []\n",
    "        for i in range(len(data0)):\n",
    "            for j in range(i+1,len(data0)):\n",
    "                tmp = self.randrow(np.concatenate((data0[i],data0[j]),axis=0))\n",
    "                tmp[:,-1] = np.where(tmp[:,-1]==feature[i],1,-1)\n",
    "                train.append(tmp)\n",
    "        \n",
    "        # 训练\n",
    "        svmset = []\n",
    "        t0 = time.time()\n",
    "        for i in tqdm(range(len(train)), desc='分类器：'):\n",
    "            train_x = train[i][:,:-1]\n",
    "            train_y = train[i][:,-1]\n",
    "            model = SVMModel(max_iter=self.max_iter, kernel_type=self.kernel_type, C=self.C, epsilon=self.epsilon)\n",
    "            model.fit(train_x,train_y)\n",
    "            svmset.append(model)\n",
    "            \n",
    "        t1 = time.time()\n",
    "        print(\"一共用时：\"+str(t1-t0)+\"s\")\n",
    "        self.svmset = svmset\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        pre = []\n",
    "        for svm in self.svmset:\n",
    "            pre.append(svm.predict(X))\n",
    "        pred = np.mat(pre[0]).T\n",
    "        for i in range(1,len(pre)):\n",
    "            pred = np.concatenate((pred,np.mat(pre[i]).T),axis=1)\n",
    "        pred = np.array(pred)\n",
    "        '''    \n",
    "        前k-1个svm如果是1则是第一个特征；\n",
    "        第1个是-1和第k到2k-3是1是第二个特征；\n",
    "        第2个和第k个是-1，和第2k-2到3k-6是1是第三个特征；\n",
    "        ……\n",
    "        对于第i个特征(i=1,...,len(feature)):\n",
    "        1的部分为从(i-1)*k-((i(i-1)/2-1))到i*k-(i^2+i)/2\n",
    "        -1的部分为第j*k-((j^2+j)/2)+i，其中j=0,1,...,i-1\n",
    "        '''\n",
    "        feature = self.feature\n",
    "        k = len(feature)\n",
    "        cnt = np.zeros((len(X), k))\n",
    "\n",
    "        for _ in range(k):\n",
    "            i = _+1\n",
    "            # 1的部分\n",
    "            for n in range(int((i-1)*k-((i*(i-1)/2-1))-1), int(i*k-(i**2+i)/2)):\n",
    "                d = np.where(pred[:,n]==1,1,0)\n",
    "                cnt[:,_] += d\n",
    "            \n",
    "            # -1的部分\n",
    "            if i==1:\n",
    "                continue #\n",
    "            else:\n",
    "                for j in range(i-1):\n",
    "                    d = np.where(pred[:,int(j*k-(((j+1)**2+(j+1))/2)+i-1)]==-1,1,0)\n",
    "                    cnt[:,_] += d\n",
    "                    \n",
    "        # 最终预测\n",
    "        predicts = feature[np.argmax(cnt, axis=1)]\n",
    "        \n",
    "        return predicts\n",
    "                \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s]\n",
      "Processing: 100%|██████████| 100/100 [01:08<00:00,  1.46it/s]\n",
      "Processing: 100%|██████████| 100/100 [01:05<00:00,  1.52it/s]\n",
      "Processing: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "Processing: 100%|██████████| 100/100 [01:07<00:00,  1.49it/s]\n",
      "Processing: 100%|██████████| 100/100 [01:06<00:00,  1.50it/s]\n",
      "分类器：: 100%|██████████| 6/6 [06:43<00:00, 67.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一共用时：403.68699979782104s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_svm = MultiSVM(max_iter = 100, epsilon=1e-5)\n",
    "model_svm.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.262"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_svm.predict(np.array(X_test))\n",
    "acc(np.array(pred), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.array(y_train)\n",
    "# y = np.mat(y).T\n",
    "# a = np.concatenate((X_train,y), axis=1)\n",
    "# # y_train.unique()\n",
    "# # a.shape\n",
    "# a = np.array(a)\n",
    "# b = np.unique(a[:,-1])\n",
    "# a[a[:,-1]==b[0]].shape\n",
    "# c = []\n",
    "# for i in b:\n",
    "#     c.append(a[a[:,-1]==i])\n",
    "# for i in range(6):\n",
    "#     for j in range(i+1,6):\n",
    "#         print(i,j)\n",
    "# np.random.permutation(np.concatenate((c[0],c[1]),axis=0)).shape\n",
    "# c[0][:,:-1].shape\n",
    "# a[a[:,-1]==3][:,-1] = 0\n",
    "# a[:,-1]=np.where(a[:,-1]==3,1,0)\n",
    "# np.concatenate(np.array([]),a)\n",
    "# b[np.argmax(a[:,:4], axis=1)]\n",
    "# pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_svm.svmset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由于实验文档里写了可以调库，就不重写了（决策树已经写了就不修改了）\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'objective':'multi:softmax',   # 多分类问题\n",
    "    'gamma':0.1,    # 用于控制是否后剪枝的参数，越大越保守，一般0.1 0.2的样子\n",
    "    'max_depth':10,  # 构建树的深度，越大越容易过拟合\n",
    "    'lambda':2,  # 控制模型复杂度的权重值的L2 正则化项参数，参数越大，模型越不容易过拟合\n",
    "    'subsample':0.7, # 随机采样训练样本\n",
    "    'silent':0,  # 设置成1 则没有运行信息输入，最好是设置成0\n",
    "    'eta':0.001,  # 如同学习率\n",
    "    'seed':1000,\n",
    "    'nthread':7,  #CPU线程数\n",
    "    #'eval_metric':'auc'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:01] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=20,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc_model=XGBClassifier(params)\n",
    "xgbc_model.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.255"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xgbc_model.predict(np.array(X_test))\n",
    "acc(np.array(pred), np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes0 = np.array(test_feature)\n",
    "tes = np.array(np.dot(V_T_kxn, np.mat(tes0).T).T)\n",
    "test_result = model_svm.predict(tes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "...     ...\n",
       "2995    1.0\n",
       "2996    1.0\n",
       "2997    1.0\n",
       "2998    1.0\n",
       "2999    0.0\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = pd.DataFrame(test_result, columns=['label'])\n",
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.to_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(xgbc_model.predict(np.array(X_train)),np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
